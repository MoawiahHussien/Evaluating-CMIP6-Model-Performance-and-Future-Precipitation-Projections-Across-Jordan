{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ac38f-506f-49a2-906d-7eb6d53f98d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "6-MODEL ENSEMBLE VALIDATION ANALYSIS\n",
      "================================================================================\n",
      "Observations directory: D:\\RICAAR\\Pr.New.Stations.Selection\\OBSERVATIONS\\monthly.mean\n",
      "Ensemble models directory: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\Models\\monthly mean according to covering and missingperiodinthestation\n",
      "Output directory: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\n",
      "--------------------------------------------------------------------------------\n",
      "Processing ensemble model: Ensemble_6Models\n",
      "Ensemble path: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\Models\\monthly mean according to covering and missingperiodinthestation\\Ensemble_6Models\n",
      "Found 49 ensemble station files\n",
      "\n",
      "Processing station 1/49: AB0004\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.984, NSE: 0.943\n",
      "  ✓ Successfully processed station AB0004\n",
      "\n",
      "Processing station 2/49: AD0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.982, NSE: 0.947\n",
      "  ✓ Successfully processed station AD0002\n",
      "\n",
      "Processing station 3/49: AD0005\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.984, NSE: 0.956\n",
      "  ✓ Successfully processed station AD0005\n",
      "\n",
      "Processing station 4/49: AD0008\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.975, NSE: 0.930\n",
      "  ✓ Successfully processed station AD0008\n",
      "\n",
      "Processing station 5/49: AD0011\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.971, NSE: 0.862\n",
      "  ✓ Successfully processed station AD0011\n",
      "\n",
      "Processing station 6/49: AD0023\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.894, NSE: -0.106\n",
      "  ✓ Successfully processed station AD0023\n",
      "\n",
      "Processing station 7/49: AD0032\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.986, NSE: 0.770\n",
      "  ✓ Successfully processed station AD0032\n",
      "\n",
      "Processing station 8/49: AE0003\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.972, NSE: 0.830\n",
      "  ✓ Successfully processed station AE0003\n",
      "\n",
      "Processing station 9/49: AE0004\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.988, NSE: 0.943\n",
      "  ✓ Successfully processed station AE0004\n",
      "\n",
      "Processing station 10/49: AH0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.979, NSE: 0.522\n",
      "  ✓ Successfully processed station AH0002\n",
      "\n",
      "Processing station 11/49: AJ0001\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.994, NSE: 0.429\n",
      "  ✓ Successfully processed station AJ0001\n",
      "\n",
      "Processing station 12/49: AL0008\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.963, NSE: 0.705\n",
      "  ✓ Successfully processed station AL0008\n",
      "\n",
      "Processing station 13/49: AL0010\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.983, NSE: 0.575\n",
      "  ✓ Successfully processed station AL0010\n",
      "\n",
      "Processing station 14/49: AL0016\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.970, NSE: 0.219\n",
      "  ✓ Successfully processed station AL0016\n",
      "\n",
      "Processing station 15/49: AL0047\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.996, NSE: 0.923\n",
      "  ✓ Successfully processed station AL0047\n",
      "\n",
      "Processing station 16/49: AL0055\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.967, NSE: 0.770\n",
      "  ✓ Successfully processed station AL0055\n",
      "\n",
      "Processing station 17/49: AL0057\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.993, NSE: 0.293\n",
      "  ✓ Successfully processed station AL0057\n",
      "\n",
      "Processing station 18/49: AL0058\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.964, NSE: 0.092\n",
      "  ✓ Successfully processed station AL0058\n",
      "\n",
      "Processing station 19/49: AM0001\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.996, NSE: 0.327\n",
      "  ✓ Successfully processed station AM0001\n",
      "\n",
      "Processing station 20/49: AM0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.984, NSE: 0.842\n",
      "  ✓ Successfully processed station AM0002\n",
      "\n",
      "Processing station 21/49: AM0006\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.994, NSE: 0.727\n",
      "  ✓ Successfully processed station AM0006\n",
      "\n",
      "Processing station 22/49: AN0003\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.994, NSE: 0.470\n",
      "  ✓ Successfully processed station AN0003\n",
      "\n",
      "Processing station 23/49: CA0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.953, NSE: 0.514\n",
      "  ✓ Successfully processed station CA0002\n",
      "\n",
      "Processing station 24/49: CA0004\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.956, NSE: 0.346\n",
      "  ✓ Successfully processed station CA0004\n",
      "\n",
      "Processing station 25/49: CA0006\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.953, NSE: 0.887\n",
      "  ✓ Successfully processed station CA0006\n",
      "\n",
      "Processing station 26/49: CC0001\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.967, NSE: 0.902\n",
      "  ✓ Successfully processed station CC0001\n",
      "\n",
      "Processing station 27/49: CC0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.968, NSE: 0.873\n",
      "  ✓ Successfully processed station CC0002\n",
      "\n",
      "Processing station 28/49: CC0004\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.968, NSE: 0.623\n",
      "  ✓ Successfully processed station CC0004\n",
      "\n",
      "Processing station 29/49: CD0005\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.942, NSE: 0.047\n",
      "  ✓ Successfully processed station CD0005\n",
      "\n",
      "Processing station 30/49: CD0007\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.957, NSE: 0.762\n",
      "  ✓ Successfully processed station CD0007\n",
      "\n",
      "Processing station 31/49: CD0009\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.959, NSE: 0.681\n",
      "  ✓ Successfully processed station CD0009\n",
      "\n",
      "Processing station 32/49: CD0010\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.967, NSE: 0.371\n",
      "  ✓ Successfully processed station CD0010\n",
      "\n",
      "Processing station 33/49: CD0011\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.879, NSE: -1.312\n",
      "  ✓ Successfully processed station CD0011\n",
      "\n",
      "Processing station 34/49: CD0029\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.965, NSE: 0.469\n",
      "  ✓ Successfully processed station CD0029\n",
      "\n",
      "Processing station 35/49: CE0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.960, NSE: 0.538\n",
      "  ✓ Successfully processed station CE0002\n",
      "\n",
      "Processing station 36/49: DB0001\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.979, NSE: 0.446\n",
      "  ✓ Successfully processed station DB0001\n",
      "\n",
      "Processing station 37/49: DB0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.992, NSE: 0.523\n",
      "  ✓ Successfully processed station DB0002\n",
      "\n",
      "Processing station 38/49: DC0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.960, NSE: 0.098\n",
      "  ✓ Successfully processed station DC0002\n",
      "\n",
      "Processing station 39/49: DG0001\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.971, NSE: 0.453\n",
      "  ✓ Successfully processed station DG0001\n",
      "\n",
      "Processing station 40/49: F 0002\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.729, NSE: -1.638\n",
      "  ✓ Successfully processed station F 0002\n",
      "\n",
      "Processing station 41/49: F 0004\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.938, NSE: 0.056\n",
      "  ✓ Successfully processed station F 0004\n",
      "\n",
      "Processing station 42/49: F 0009\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.901, NSE: -7.603\n",
      "  ✓ Successfully processed station F 0009\n",
      "\n",
      "Processing station 43/49: F 0011\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.549, NSE: -0.605\n",
      "  ✓ Successfully processed station F 0011\n",
      "\n",
      "Processing station 44/49: G 0004\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.930, NSE: 0.148\n",
      "  ✓ Successfully processed station G 0004\n",
      "\n",
      "Processing station 45/49: G 0005\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.925, NSE: 0.388\n",
      "  ✓ Successfully processed station G 0005\n",
      "\n",
      "Processing station 46/49: G 0006\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.785, NSE: -0.095\n",
      "  ✓ Successfully processed station G 0006\n",
      "\n",
      "Processing station 47/49: G 0007\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.506, NSE: -3.763\n",
      "  ✓ Successfully processed station G 0007\n",
      "\n",
      "Processing station 48/49: G 0009\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.959, NSE: 0.627\n",
      "  ✓ Successfully processed station G 0009\n",
      "\n",
      "Processing station 49/49: H 0001\n",
      "  Loaded data - Ensemble: 8 months, Observations: 12 months\n",
      "  Metrics calculated - Coverage: 0.67, r: 0.881, NSE: -1.339\n",
      "  ✓ Successfully processed station H 0001\n",
      "\n",
      "============================================================\n",
      "VALIDATION SUMMARY\n",
      "============================================================\n",
      "Total stations found: 49\n",
      "Successfully processed: 49\n",
      "Errors/missing data: 0\n",
      "Success rate: 100.0%\n",
      "\n",
      "Overall Performance Statistics:\n",
      "Average Correlation (r): 0.937 ± 0.099\n",
      "Average NSE: 0.150 ± 1.403\n",
      "Average RMSE: 12.8 ± 8.2\n",
      "Average Coverage: 0.67 ± 0.00\n",
      "\n",
      "Saving results to: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\\ensemble_6models_validation_results.xlsx\n",
      "\n",
      "Creating validation plots...\n",
      "✓ All validation plots created successfully!\n",
      "✓ Validation analysis complete!\n",
      "\n",
      "============================================================\n",
      "VALIDATION COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Results saved to: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\n",
      "Files created:\n",
      "  - ensemble_6models_validation_results.xlsx\n",
      "  - ensemble_performance_distribution.png\n",
      "  - ensemble_performance_relationships.png\n",
      "  - ensemble_coverage_pattern.png\n",
      "  - ensemble_station_performance.png (if ≥10 stations)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_temporal_coverage(obs_data, model_data):\n",
    "    \"\"\"Analyze temporal coverage with aligned data\"\"\"\n",
    "    # \n",
    "    merged_data = pd.merge(obs_data, model_data, \n",
    "                          on=['Month'], \n",
    "                          suffixes=('_obs', '_model'))\n",
    "    \n",
    "    metrics = {}\n",
    "    total_months = 12\n",
    "    valid_months = np.sum(~np.isnan(merged_data['Rainfall_obs']))\n",
    "    \n",
    "    metrics['Coverage_Ratio'] = valid_months / total_months\n",
    "    metrics['Valid_Months'] = valid_months\n",
    "    metrics['Missing_Months'] = total_months - valid_months\n",
    "    \n",
    "    # Calculate metrics for months\n",
    "    valid_mask = ~np.isnan(merged_data['Rainfall_obs'])\n",
    "    if np.sum(valid_mask) > 0:\n",
    "        obs_values = merged_data.loc[valid_mask, 'Rainfall_obs']\n",
    "        model_values = merged_data.loc[valid_mask, 'Rainfall_model']\n",
    "        \n",
    "        metrics['r'] = stats.pearsonr(obs_values, model_values)[0]\n",
    "        metrics['RMSE'] = np.sqrt(np.mean((model_values - obs_values) ** 2))\n",
    "        metrics['MAE'] = np.mean(np.abs(model_values - obs_values))\n",
    "        metrics['PBIAS'] = 100 * np.sum(model_values - obs_values) / np.sum(obs_values)\n",
    "        metrics['NSE'] = 1 - (np.sum((model_values - obs_values) ** 2) / \n",
    "                             np.sum((obs_values - obs_values.mean()) ** 2))\n",
    "    else:\n",
    "        metrics.update({'r': np.nan, 'RMSE': np.nan, 'MAE': np.nan, 'PBIAS': np.nan, 'NSE': np.nan})\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def process_ensemble_validation(obs_dir, ensemble_models_dir, output_dir):\n",
    "    \"\"\"Process validation for 6-model ensemble data against observations\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"6-MODEL ENSEMBLE VALIDATION ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Observations directory: {obs_dir}\")\n",
    "    print(f\"Ensemble models directory: {ensemble_models_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    validation_results = []\n",
    "    coverage_patterns = []\n",
    "    error_stations = []\n",
    "    \n",
    "    # Look for the Ensemble_6Models subdirectory\n",
    "    ensemble_path = os.path.join(ensemble_models_dir, 'Ensemble_6Models')\n",
    "    if not os.path.exists(ensemble_path):\n",
    "        print(f\"ERROR: Ensemble_6Models directory not found at {ensemble_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Processing ensemble model: Ensemble_6Models\")\n",
    "    print(f\"Ensemble path: {ensemble_path}\")\n",
    "    \n",
    "    # Get list of ensemble station files\n",
    "    ensemble_files = [f for f in os.listdir(ensemble_path) if f.endswith('.xlsx')]\n",
    "    total_stations = len(ensemble_files)\n",
    "    processed_stations = 0\n",
    "    \n",
    "    print(f\"Found {total_stations} ensemble station files\")\n",
    "    \n",
    "    for station_file in ensemble_files:\n",
    "        if not station_file.startswith('Station_') or not station_file.endswith('.xlsx'):\n",
    "            continue\n",
    "            \n",
    "        # Extract station ID from filename: Station_{STATION_ID}_Daily_Rainfall.xlsx\n",
    "        try:\n",
    "            station_id = station_file.split('_')[1]\n",
    "        except IndexError:\n",
    "            print(f\"Warning: Could not extract station ID from {station_file}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing station {processed_stations + 1}/{total_stations}: {station_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Read ensemble model data\n",
    "            ensemble_file_path = os.path.join(ensemble_path, station_file)\n",
    "            model_data = pd.read_excel(ensemble_file_path, sheet_name='Monthly_Averages')\n",
    "            \n",
    "            # Read corresponding observation data\n",
    "            obs_file = os.path.join(obs_dir, f'Station_{station_id}_Daily_Rainfall.xlsx')\n",
    "            if not os.path.exists(obs_file):\n",
    "                print(f\"  Warning: No observation file found for station {station_id}\")\n",
    "                error_stations.append({'Station_ID': station_id, 'Error': 'No observation file'})\n",
    "                continue\n",
    "                \n",
    "            obs_data = pd.read_excel(obs_file, sheet_name='Monthly_Averages')\n",
    "            \n",
    "            print(f\"  Loaded data - Ensemble: {len(model_data)} months, Observations: {len(obs_data)} months\")\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            metrics = analyze_temporal_coverage(obs_data, model_data)\n",
    "            \n",
    "            print(f\"  Metrics calculated - Coverage: {metrics['Coverage_Ratio']:.2f}, r: {metrics['r']:.3f}, NSE: {metrics['NSE']:.3f}\")\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'Model': 'Ensemble_6Models',\n",
    "                'Station_ID': station_id,\n",
    "                'Station_Name': model_data['Station_Name'].iloc[0] if 'Station_Name' in model_data.columns else f'Station_{station_id}',\n",
    "                'Latitude': model_data['Latitude'].iloc[0] if 'Latitude' in model_data.columns else np.nan,\n",
    "                'Longitude': model_data['Longitude'].iloc[0] if 'Longitude' in model_data.columns else np.nan,\n",
    "                **metrics\n",
    "            }\n",
    "            validation_results.append(result)\n",
    "            \n",
    "            # Store coverage patterns for detailed analysis\n",
    "            # Merge obs and model data to get coverage pattern\n",
    "            merged_coverage = pd.merge(obs_data[['Month', 'Rainfall']], \n",
    "                                     model_data[['Month', 'Rainfall']], \n",
    "                                     on='Month', suffixes=('_obs', '_model'))\n",
    "            \n",
    "            coverage_pattern = pd.DataFrame({\n",
    "                'Model': 'Ensemble_6Models',\n",
    "                'Station_ID': station_id,\n",
    "                'Month': merged_coverage['Month'],\n",
    "                'Is_Valid': ~np.isnan(merged_coverage['Rainfall_obs']),\n",
    "                'Has_Model_Data': ~np.isnan(merged_coverage['Rainfall_model']),\n",
    "                'Obs_Rainfall': merged_coverage['Rainfall_obs'],\n",
    "                'Model_Rainfall': merged_coverage['Rainfall_model']\n",
    "            })\n",
    "            coverage_patterns.append(coverage_pattern)\n",
    "            \n",
    "            processed_stations += 1\n",
    "            print(f\"  ✓ Successfully processed station {station_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error processing station {station_id}: {str(e)}\")\n",
    "            error_stations.append({'Station_ID': station_id, 'Error': str(e)})\n",
    "            import traceback\n",
    "            print(f\"  Error details: {traceback.format_exc()}\")\n",
    "            continue\n",
    "    \n",
    "    if not validation_results:\n",
    "        print(\"ERROR: No stations were successfully processed!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Combine results\n",
    "    validation_df = pd.DataFrame(validation_results)\n",
    "    coverage_df = pd.concat(coverage_patterns, ignore_index=True)\n",
    "    error_df = pd.DataFrame(error_stations)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"VALIDATION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total stations found: {total_stations}\")\n",
    "    print(f\"Successfully processed: {processed_stations}\")\n",
    "    print(f\"Errors/missing data: {len(error_stations)}\")\n",
    "    print(f\"Success rate: {processed_stations/total_stations*100:.1f}%\")\n",
    "    \n",
    "    # Print overall statistics\n",
    "    if len(validation_df) > 0:\n",
    "        print(f\"\\nOverall Performance Statistics:\")\n",
    "        print(f\"Average Correlation (r): {validation_df['r'].mean():.3f} ± {validation_df['r'].std():.3f}\")\n",
    "        print(f\"Average NSE: {validation_df['NSE'].mean():.3f} ± {validation_df['NSE'].std():.3f}\")\n",
    "        print(f\"Average RMSE: {validation_df['RMSE'].mean():.1f} ± {validation_df['RMSE'].std():.1f}\")\n",
    "        print(f\"Average Coverage: {validation_df['Coverage_Ratio'].mean():.2f} ± {validation_df['Coverage_Ratio'].std():.2f}\")\n",
    "    \n",
    "    # Save results\n",
    "    output_file = os.path.join(output_dir, 'ensemble_6models_validation_results.xlsx')\n",
    "    print(f\"\\nSaving results to: {output_file}\")\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        validation_df.to_excel(writer, sheet_name='Validation_Metrics', index=False)\n",
    "        coverage_df.to_excel(writer, sheet_name='Coverage_Patterns', index=False)\n",
    "        if len(error_df) > 0:\n",
    "            error_df.to_excel(writer, sheet_name='Processing_Errors', index=False)\n",
    "        \n",
    "        # Add summary statistics\n",
    "        summary_stats = validation_df[['r', 'RMSE', 'MAE', 'PBIAS', 'NSE', 'Coverage_Ratio']].describe()\n",
    "        summary_stats.to_excel(writer, sheet_name='Summary_Statistics')\n",
    "    \n",
    "    # Create validation plots\n",
    "    create_ensemble_validation_plots(validation_df, coverage_df, output_dir)\n",
    "    \n",
    "    print(f\"✓ Validation analysis complete!\")\n",
    "    \n",
    "    return validation_df, coverage_df\n",
    "\n",
    "def create_ensemble_validation_plots(validation_df, coverage_df, output_dir):\n",
    "    \"\"\"Create validation plots specifically for ensemble model\"\"\"\n",
    "    \n",
    "    print(\"\\nCreating validation plots...\")\n",
    "    \n",
    "    # Set basic plot style\n",
    "    plt.rcParams['figure.figsize'] = [12, 8]\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['grid.alpha'] = 0.3\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "    \n",
    "    # 1. Performance metrics distribution\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    metrics = ['r', 'RMSE', 'MAE', 'NSE', 'PBIAS', 'Coverage_Ratio']\n",
    "    colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold', 'violet', 'orange']\n",
    "    \n",
    "    for ax, metric, color in zip(axes.flat, metrics, colors):\n",
    "        valid_data = validation_df[metric].dropna()\n",
    "        if len(valid_data) > 0:\n",
    "            ax.hist(valid_data, bins=15, alpha=0.7, color=color, edgecolor='black')\n",
    "            ax.set_title(f'{metric} Distribution\\n(n={len(valid_data)}, mean={valid_data.mean():.3f})', \n",
    "                        fontsize=12, pad=10)\n",
    "            ax.set_xlabel(metric)\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f'{metric} - No Data Available')\n",
    "    \n",
    "    plt.suptitle('6-Model Ensemble Performance Metrics Distribution', fontsize=16, y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'ensemble_performance_distribution.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Scatter plots for key relationships\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Correlation vs NSE\n",
    "    ax = axes[0, 0]\n",
    "    ax.scatter(validation_df['r'], validation_df['NSE'], alpha=0.6, s=60, color='blue')\n",
    "    ax.set_xlabel('Correlation (r)')\n",
    "    ax.set_ylabel('Nash-Sutcliffe Efficiency (NSE)')\n",
    "    ax.set_title('Correlation vs NSE')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Coverage vs Performance\n",
    "    ax = axes[0, 1]\n",
    "    ax.scatter(validation_df['Coverage_Ratio'], validation_df['r'], alpha=0.6, s=60, color='green')\n",
    "    ax.set_xlabel('Coverage Ratio')\n",
    "    ax.set_ylabel('Correlation (r)')\n",
    "    ax.set_title('Coverage vs Correlation')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # PBIAS vs NSE\n",
    "    ax = axes[1, 0]\n",
    "    ax.scatter(validation_df['PBIAS'], validation_df['NSE'], alpha=0.6, s=60, color='red')\n",
    "    ax.set_xlabel('PBIAS (%)')\n",
    "    ax.set_ylabel('Nash-Sutcliffe Efficiency (NSE)')\n",
    "    ax.set_title('PBIAS vs NSE')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # RMSE vs MAE\n",
    "    ax = axes[1, 1]\n",
    "    ax.scatter(validation_df['RMSE'], validation_df['MAE'], alpha=0.6, s=60, color='purple')\n",
    "    ax.set_xlabel('RMSE')\n",
    "    ax.set_ylabel('MAE')\n",
    "    ax.set_title('RMSE vs MAE')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('6-Model Ensemble Performance Relationships', fontsize=16, y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'ensemble_performance_relationships.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Coverage pattern visualization\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create coverage matrix\n",
    "    coverage_matrix = coverage_df.pivot_table(\n",
    "        values='Is_Valid', \n",
    "        index='Station_ID',\n",
    "        columns='Month',\n",
    "        aggfunc='first'\n",
    "    )\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(coverage_matrix, \n",
    "                cmap='RdYlBu_r', \n",
    "                cbar_kws={'label': 'Data Available (1=Yes, 0=No)'},\n",
    "                linewidths=0.5,\n",
    "                linecolor='white')\n",
    "    \n",
    "    plt.title('Data Coverage Pattern by Station and Month\\n6-Model Ensemble vs Observations', \n",
    "              fontsize=14, pad=20)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Station ID')\n",
    "    plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'ensemble_coverage_pattern.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Performance by station (top/bottom performers)\n",
    "    if len(validation_df) >= 10:  # Only if we have enough stations\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        \n",
    "        # Sort by correlation\n",
    "        sorted_df = validation_df.sort_values('r', ascending=True)\n",
    "        \n",
    "        # Plot top and bottom 10 stations\n",
    "        n_show = min(10, len(sorted_df) // 2)\n",
    "        plot_df = pd.concat([sorted_df.head(n_show), sorted_df.tail(n_show)])\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "        \n",
    "        # Correlation plot\n",
    "        colors = ['red' if r < 0.5 else 'orange' if r < 0.7 else 'green' for r in plot_df['r']]\n",
    "        bars1 = ax1.barh(range(len(plot_df)), plot_df['r'], color=colors, alpha=0.7)\n",
    "        ax1.set_yticks(range(len(plot_df)))\n",
    "        ax1.set_yticklabels(plot_df['Station_ID'])\n",
    "        ax1.set_xlabel('Correlation (r)')\n",
    "        ax1.set_title(f'Correlation by Station (Top & Bottom {n_show})')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        ax1.axvline(x=0.5, color='orange', linestyle='--', alpha=0.5, label='r=0.5')\n",
    "        ax1.axvline(x=0.7, color='green', linestyle='--', alpha=0.5, label='r=0.7')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # NSE plot\n",
    "        colors = ['red' if nse < 0 else 'orange' if nse < 0.5 else 'green' for nse in plot_df['NSE']]\n",
    "        bars2 = ax2.barh(range(len(plot_df)), plot_df['NSE'], color=colors, alpha=0.7)\n",
    "        ax2.set_yticks(range(len(plot_df)))\n",
    "        ax2.set_yticklabels(plot_df['Station_ID'])\n",
    "        ax2.set_xlabel('Nash-Sutcliffe Efficiency (NSE)')\n",
    "        ax2.set_title(f'NSE by Station (Top & Bottom {n_show})')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        ax2.axvline(x=0.5, color='orange', linestyle='--', alpha=0.5, label='NSE=0.5')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.suptitle('Station-wise Performance Analysis - 6-Model Ensemble', fontsize=16, y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'ensemble_station_performance.png'), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"✓ All validation plots created successfully!\")\n",
    "\n",
    "# Define directories\n",
    "obs_dir = r'D:\\RICAAR\\Pr.New.Stations.Selection\\OBSERVATIONS\\monthly.mean'\n",
    "ensemble_models_dir = r'D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\Models\\monthly mean.Models'\n",
    "output_dir = r'D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results'\n",
    "\n",
    "# Run ensemble validation\n",
    "if __name__ == \"__main__\":\n",
    "    validation_results, coverage_patterns = process_ensemble_validation(obs_dir, ensemble_models_dir, output_dir)\n",
    "    \n",
    "    if validation_results is not None:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"VALIDATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Results saved to: {output_dir}\")\n",
    "        print(\"Files created:\")\n",
    "        print(\"  - ensemble_6models_validation_results.xlsx\")\n",
    "        print(\"  - ensemble_performance_distribution.png\") \n",
    "        print(\"  - ensemble_performance_relationships.png\")\n",
    "        print(\"  - ensemble_coverage_pattern.png\")\n",
    "        print(\"  - ensemble_station_performance.png (if ≥10 stations)\")\n",
    "    else:\n",
    "        print(\"ERROR: Validation failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
