{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc5a46b-7e28-4278-aa4c-c43aa2409920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SSP 8.5 ENSEMBLE PRECIPITATION ANALYSIS\n",
      "============================================================\n",
      "Input directory: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\n",
      "Output directory: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\n",
      "Basin shapefile: D:\\RICAAR\\surfacebasin\\surface_basin.shp\n",
      "Jordan shapefile: D:\\RICAAR\\Governorates\\JordanwithGovernorates.shp\n",
      "\n",
      "Initializing SSP 8.5 ensemble precipitation analysis...\n",
      "Reading shapefiles...\n",
      "Processing 16 basins...\n",
      "Loading and concatenating SSP 8.5 ensemble files...\n",
      "Loading ensemble_precipitation_6models_ssp85_1961_1994.nc...\n",
      "  Time range: 1961-01-01 to 1994-12-31\n",
      "  Time steps: 12418\n",
      "  Size: 0.6 GB\n",
      "Loading ensemble_precipitation_6models_ssp85_1995_2014.nc...\n",
      "  Time range: 1995-01-01 to 2014-12-31\n",
      "  Time steps: 7305\n",
      "  Size: 0.3 GB\n",
      "Loading ensemble_precipitation_6models_ssp85_2015_2020.nc...\n",
      "  Time range: 2015-01-01 to 2020-12-31\n",
      "  Time steps: 2192\n",
      "  Size: 0.1 GB\n",
      "Loading ensemble_precipitation_6models_ssp85_2021_2040.nc...\n",
      "  Time range: 2021-01-01 to 2040-12-31\n",
      "  Time steps: 7305\n",
      "  Size: 0.3 GB\n",
      "Loading ensemble_precipitation_6models_ssp85_2041_2060.nc...\n",
      "  Time range: 2041-01-01 to 2060-12-31\n",
      "  Time steps: 7305\n",
      "  Size: 0.3 GB\n",
      "Loading ensemble_precipitation_6models_ssp85_2061_2070.nc...\n",
      "  Time range: 2061-01-01 to 2070-12-31\n",
      "  Time steps: 3652\n",
      "  Size: 0.2 GB\n",
      "\n",
      "Concatenating 6 datasets...\n",
      "Combined dataset:\n",
      "  Total time range: 1961-01-01 to 2070-12-31\n",
      "  Total time steps: 40177\n",
      "  Total size: 1.9 GB\n",
      "\n",
      "Processing reference period (1995-2014)...\n",
      "  Selected 7305 time steps for reference\n",
      "  Processing basin: HAMMAD\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: YARMOUK (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: J.VALLEY-YARMOUK TRIANGLE\n",
      "    Processing wet season...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_21552\\76375471.py:165: UserWarning: No gridpoint belongs to any region. Returning an all-NaN mask.\n",
      "  basin_mask = regionmask.mask_geopandas(basin_gdf, period_ds.lon, period_ds.lat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing dry season...\n",
      "  Processing basin: JORDAN VALLY (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: N.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AZRAQ (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AMMAN ZARQA (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: MUJIB\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: D.S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: W. ARABA NORTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: HASA\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: JAFER\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: WADI ARABA SOUTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: QA DISI & SOUTHERN DESERT\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: SARHAN\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "\n",
      "Processing near_future period (2021-2040)...\n",
      "  Selected 7305 time steps for near_future\n",
      "  Processing basin: HAMMAD\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: YARMOUK (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: J.VALLEY-YARMOUK TRIANGLE\n",
      "    Processing wet season...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_21552\\76375471.py:165: UserWarning: No gridpoint belongs to any region. Returning an all-NaN mask.\n",
      "  basin_mask = regionmask.mask_geopandas(basin_gdf, period_ds.lon, period_ds.lat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing dry season...\n",
      "  Processing basin: JORDAN VALLY (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: N.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AZRAQ (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AMMAN ZARQA (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: MUJIB\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: D.S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: W. ARABA NORTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: HASA\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: JAFER\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: WADI ARABA SOUTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: QA DISI & SOUTHERN DESERT\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: SARHAN\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "\n",
      "Processing mid_future period (2041-2060)...\n",
      "  Selected 7305 time steps for mid_future\n",
      "  Processing basin: HAMMAD\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: YARMOUK (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: J.VALLEY-YARMOUK TRIANGLE\n",
      "    Processing wet season...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_21552\\76375471.py:165: UserWarning: No gridpoint belongs to any region. Returning an all-NaN mask.\n",
      "  basin_mask = regionmask.mask_geopandas(basin_gdf, period_ds.lon, period_ds.lat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing dry season...\n",
      "  Processing basin: JORDAN VALLY (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: N.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AZRAQ (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AMMAN ZARQA (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: MUJIB\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: D.S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: W. ARABA NORTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: HASA\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: JAFER\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: WADI ARABA SOUTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: QA DISI & SOUTHERN DESERT\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: SARHAN\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "\n",
      "Processing far_future period (2061-2070)...\n",
      "  Selected 3652 time steps for far_future\n",
      "  Processing basin: HAMMAD\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: YARMOUK (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: J.VALLEY-YARMOUK TRIANGLE\n",
      "    Processing wet season...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_21552\\76375471.py:165: UserWarning: No gridpoint belongs to any region. Returning an all-NaN mask.\n",
      "  basin_mask = regionmask.mask_geopandas(basin_gdf, period_ds.lon, period_ds.lat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing dry season...\n",
      "  Processing basin: JORDAN VALLY (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: N.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AZRAQ (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: AMMAN ZARQA (JORDAN)\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: MUJIB\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: D.S.R.S.W\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: W. ARABA NORTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: HASA\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: JAFER\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: WADI ARABA SOUTH\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: QA DISI & SOUTHERN DESERT\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "  Processing basin: SARHAN\n",
      "    Processing wet season...\n",
      "    Processing dry season...\n",
      "\n",
      "Saving SSP 8.5 ensemble results...\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_reference_wet_season_mmpermonth.nc\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_reference_dry_season_mmpermonth.nc\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_near_future_wet_season_mmpermonth.nc\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_near_future_dry_season_mmpermonth.nc\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_mid_future_wet_season_mmpermonth.nc\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_mid_future_dry_season_mmpermonth.nc\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_far_future_wet_season_mmpermonth.nc\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\precipitation_ssp85_ensemble_far_future_dry_season_mmpermonth.nc\n",
      "\n",
      "SSP 8.5 ensemble analysis complete!\n",
      "Total files saved: 8\n",
      "Results saved in: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\n",
      "Analysis summary saved to: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\ssp85_seasonal_analysis_summary.txt\n",
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "Successfully processed SSP 8.5 ensemble data\n",
      "Files created: 8\n",
      "Output location: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\n",
      "\n",
      "SSP 8.5 ensemble seasonal analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import regionmask\n",
    "\n",
    "def calculate_seasonal_monthly_means(ds, start_year, end_year, season_type):\n",
    "    \"\"\"Calculate mean monthly precipitation for a season across years\"\"\"\n",
    "    if season_type == 'wet':\n",
    "        season_means = []\n",
    "        for year in range(start_year, end_year):\n",
    "            oct_dec = ds.sel(time=slice(f\"{year}-10-01\", f\"{year}-12-31\"))\n",
    "            jan_mar = ds.sel(time=slice(f\"{year+1}-01-01\", f\"{year+1}-03-31\"))\n",
    "            \n",
    "            if len(oct_dec.time) > 0 and len(jan_mar.time) > 0:\n",
    "                monthly_means = []\n",
    "                \n",
    "                # Process Oct-Dec\n",
    "                for month in [10, 11, 12]:\n",
    "                    month_data = oct_dec.sel(time=oct_dec.time.dt.month == month)\n",
    "                    if len(month_data.time) > 0:\n",
    "                        days_in_month = month_data.time.dt.days_in_month[0].values\n",
    "                        month_mean = month_data.sum('time') * (30 / days_in_month)\n",
    "                        monthly_means.append(month_mean)\n",
    "                \n",
    "                # Process Jan-Mar\n",
    "                for month in [1, 2, 3]:\n",
    "                    month_data = jan_mar.sel(time=jan_mar.time.dt.month == month)\n",
    "                    if len(month_data.time) > 0:\n",
    "                        days_in_month = month_data.time.dt.days_in_month[0].values\n",
    "                        month_mean = month_data.sum('time') * (30 / days_in_month)\n",
    "                        monthly_means.append(month_mean)\n",
    "                \n",
    "                if monthly_means:\n",
    "                    season_means.append(sum(monthly_means) / len(monthly_means))\n",
    "        \n",
    "        if season_means:\n",
    "            return sum(season_means) / len(season_means)\n",
    "        return None\n",
    "    \n",
    "    else:  # dry season\n",
    "        season_means = []\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            monthly_means = []\n",
    "            season = ds.sel(time=slice(f\"{year}-04-01\", f\"{year}-09-30\"))\n",
    "            \n",
    "            for month in range(4, 10):\n",
    "                month_data = season.sel(time=season.time.dt.month == month)\n",
    "                if len(month_data.time) > 0:\n",
    "                    days_in_month = month_data.time.dt.days_in_month[0].values\n",
    "                    month_mean = month_data.sum('time') * (30 / days_in_month)\n",
    "                    monthly_means.append(month_mean)\n",
    "            \n",
    "            if monthly_means:\n",
    "                season_means.append(sum(monthly_means) / len(monthly_means))\n",
    "        \n",
    "        if season_means:\n",
    "            return sum(season_means) / len(season_means)\n",
    "        return None\n",
    "\n",
    "def load_and_concatenate_ensemble_files(input_dir):\n",
    "    \"\"\"Load and concatenate all 6 SSP 8.5 ensemble NetCDF files\"\"\"\n",
    "    print(\"Loading and concatenating SSP 8.5 ensemble files...\")\n",
    "    \n",
    "    # Define the expected file pattern for SSP 8.5 ensemble files\n",
    "    file_patterns = [\n",
    "        \"ensemble_precipitation_6models_ssp85_1961_1994.nc\",\n",
    "        \"ensemble_precipitation_6models_ssp85_1995_2014.nc\", \n",
    "        \"ensemble_precipitation_6models_ssp85_2015_2020.nc\",\n",
    "        \"ensemble_precipitation_6models_ssp85_2021_2040.nc\",\n",
    "        \"ensemble_precipitation_6models_ssp85_2041_2060.nc\",\n",
    "        \"ensemble_precipitation_6models_ssp85_2061_2070.nc\"\n",
    "    ]\n",
    "    \n",
    "    datasets = []\n",
    "    total_size = 0\n",
    "    \n",
    "    for pattern in file_patterns:\n",
    "        file_path = Path(input_dir) / pattern\n",
    "        if file_path.exists():\n",
    "            print(f\"Loading {pattern}...\")\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            datasets.append(ds)\n",
    "            \n",
    "            # Calculate file size\n",
    "            file_size = file_path.stat().st_size / (1024**3)  # GB\n",
    "            total_size += file_size\n",
    "            print(f\"  Time range: {pd.to_datetime(ds.time.values[0]).strftime('%Y-%m-%d')} to {pd.to_datetime(ds.time.values[-1]).strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Time steps: {len(ds.time)}\")\n",
    "            print(f\"  Size: {file_size:.1f} GB\")\n",
    "        else:\n",
    "            print(f\"Warning: File {pattern} not found in {input_dir}\")\n",
    "    \n",
    "    if not datasets:\n",
    "        raise FileNotFoundError(\"No SSP 8.5 ensemble files found!\")\n",
    "    \n",
    "    print(f\"\\nConcatenating {len(datasets)} datasets...\")\n",
    "    combined_ds = xr.concat(datasets, dim='time')\n",
    "    \n",
    "    print(f\"Combined dataset:\")\n",
    "    print(f\"  Total time range: {pd.to_datetime(combined_ds.time.values[0]).strftime('%Y-%m-%d')} to {pd.to_datetime(combined_ds.time.values[-1]).strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Total time steps: {len(combined_ds.time)}\")\n",
    "    print(f\"  Total size: {total_size:.1f} GB\")\n",
    "    \n",
    "    return combined_ds\n",
    "\n",
    "def process_precipitation_data(input_dir, output_dir, basin_shapefile, gov_shapefile):\n",
    "    \"\"\"Process precipitation data for SSP 8.5 ensemble scenario and save results\"\"\"\n",
    "    print(\"\\nInitializing SSP 8.5 ensemble precipitation analysis...\")\n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define periods for SSP 8.5 - matching your ensemble file structure\n",
    "    periods = {\n",
    "        'reference': (1995, 2014),\n",
    "        'near_future': (2021, 2040), \n",
    "        'mid_future': (2041, 2060),\n",
    "        'far_future': (2061, 2070)\n",
    "    }\n",
    "\n",
    "    print(\"Reading shapefiles...\")\n",
    "    basins = gpd.read_file(basin_shapefile)\n",
    "    basins = basins.to_crs(epsg=4326)\n",
    "    jordan = gpd.read_file(gov_shapefile)\n",
    "    jordan = jordan.to_crs(epsg=4326)\n",
    "\n",
    "    # Filter basins\n",
    "    exclude_basins = ['JVALLEYYARMOUKTRIANGLE']\n",
    "    basins = basins[~basins['BASIN_NAME'].isin(exclude_basins)]\n",
    "    basins = basins[~basins['BASIN_NAME'].str.contains(\"SYRIA\", case=False, na=False)]\n",
    "\n",
    "    print(f\"Processing {len(basins)} basins...\")\n",
    "\n",
    "    # Load the complete ensemble dataset\n",
    "    try:\n",
    "        combined_ds = load_and_concatenate_ensemble_files(input_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ensemble files: {e}\")\n",
    "        return\n",
    "\n",
    "    combined_data = {\n",
    "        period: {season: None for season in ['wet', 'dry']}\n",
    "        for period in periods.keys()\n",
    "    }\n",
    "\n",
    "    # Process each period using the combined ensemble dataset\n",
    "    for period_name, (start_year, end_year) in periods.items():\n",
    "        print(f\"\\nProcessing {period_name} period ({start_year}-{end_year})...\")\n",
    "        \n",
    "        try:\n",
    "            # Select data for the specific period\n",
    "            period_ds = combined_ds.sel(time=slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\"))\n",
    "            \n",
    "            if len(period_ds.time) == 0:\n",
    "                print(f\"Warning: No data found for period {period_name}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  Selected {len(period_ds.time)} time steps for {period_name}\")\n",
    "            \n",
    "            for basin_idx, basin in basins.iterrows():\n",
    "                print(f\"  Processing basin: {basin['BASIN_NAME']}\")\n",
    "                basin_gdf = gpd.GeoDataFrame(geometry=[basin.geometry])\n",
    "                basin_mask = regionmask.mask_geopandas(basin_gdf, period_ds.lon, period_ds.lat)\n",
    "                \n",
    "                for season in ['wet', 'dry']:\n",
    "                    print(f\"    Processing {season} season...\")\n",
    "                    seasonal_mean = calculate_seasonal_monthly_means(\n",
    "                        period_ds, start_year, end_year, season\n",
    "                    )\n",
    "                    \n",
    "                    if seasonal_mean is not None:\n",
    "                        masked_data = seasonal_mean.where(~basin_mask.isnull())\n",
    "                        \n",
    "                        if combined_data[period_name][season] is None:\n",
    "                            combined_data[period_name][season] = masked_data\n",
    "                        else:\n",
    "                            combined_data[period_name][season] = xr.where(\n",
    "                                ~masked_data.isnull(),\n",
    "                                masked_data,\n",
    "                                combined_data[period_name][season]\n",
    "                            )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing period {period_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\nSaving SSP 8.5 ensemble results...\")\n",
    "    saved_files = []\n",
    "    \n",
    "    for period_name, seasons_data in combined_data.items():\n",
    "        for season, data in seasons_data.items():\n",
    "            if data is not None:\n",
    "                nc_output = output_dir / f\"precipitation_ssp85_ensemble_{period_name}_{season}_season_mmpermonth.nc\"\n",
    "                \n",
    "                # Add metadata to the output\n",
    "                data.attrs['scenario'] = 'SSP 8.5'\n",
    "                data.attrs['source'] = '6-model ensemble average'\n",
    "                data.attrs['period'] = f\"{periods[period_name][0]}-{periods[period_name][1]}\"\n",
    "                data.attrs['season'] = season\n",
    "                data.attrs['units'] = 'mm/month'\n",
    "                data.attrs['description'] = f'Mean monthly precipitation for {season} season from SSP 8.5 ensemble'\n",
    "                data.attrs['processing_date'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                data.attrs['models_used'] = 'CMCC-CM2-SR5, CNRM-ESM2-1, EC-Earth3-Veg, IPSL-CM6A-LR, MPI-ESM1-2-LR, NorESM2-MM'\n",
    "                data.attrs['ensemble_method'] = '6-model uniform ensemble'\n",
    "                \n",
    "                data.to_netcdf(nc_output)\n",
    "                saved_files.append(nc_output)\n",
    "                print(f\"  Saved {nc_output}\")\n",
    "    \n",
    "    # Close the combined dataset\n",
    "    combined_ds.close()\n",
    "    \n",
    "    print(f\"\\nSSP 8.5 ensemble analysis complete!\")\n",
    "    print(f\"Total files saved: {len(saved_files)}\")\n",
    "    print(f\"Results saved in: {output_dir}\")\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "def create_analysis_summary(output_dir, saved_files):\n",
    "    \"\"\"Create a summary report of the seasonal analysis\"\"\"\n",
    "    summary_content = f\"\"\"\n",
    "# SSP 8.5 Ensemble Seasonal Precipitation Analysis Summary\n",
    "Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Analysis Details:\n",
    "- Scenario: SSP 8.5\n",
    "- Source: 6-model ensemble average\n",
    "- Models: CMCC-CM2-SR5, CNRM-ESM2-1, EC-Earth3-Veg, IPSL-CM6A-LR, MPI-ESM1-2-LR, NorESM2-MM\n",
    "\n",
    "## Time Periods Analyzed:\n",
    "1. Reference: 1995-2014\n",
    "2. Near Future: 2021-2040\n",
    "3. Mid Future: 2041-2060\n",
    "4. Far Future: 2061-2070\n",
    "\n",
    "## Seasons:\n",
    "- Wet Season: October-March (6 months)\n",
    "- Dry Season: April-September (6 months)\n",
    "\n",
    "## Output Files Generated ({len(saved_files)} files):\n",
    "{chr(10).join(f\"- {file.name}\" for file in saved_files)}\n",
    "\n",
    "## Processing Method:\n",
    "1. Load and concatenate 6 ensemble NetCDF files\n",
    "2. Extract seasonal data for each time period\n",
    "3. Calculate monthly means normalized to 30-day months\n",
    "4. Apply basin masks using regionmask\n",
    "5. Generate seasonal precipitation grids\n",
    "\n",
    "## Output Format:\n",
    "- Variable: Precipitation (mm/month)\n",
    "- Grid: Same as source ensemble files\n",
    "- Coordinate System: EPSG:4326 (WGS84)\n",
    "- Coverage: Jordan basins (Syria basins excluded)\n",
    "\n",
    "## Usage:\n",
    "These files can be used for:\n",
    "- Climate change impact assessment\n",
    "- Seasonal precipitation trend analysis\n",
    "- Water resource planning\n",
    "- Agricultural planning\n",
    "- Comparative analysis with other scenarios\n",
    "\"\"\"\n",
    "    \n",
    "    summary_path = Path(output_dir) / 'ssp85_seasonal_analysis_summary.txt'\n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(summary_content)\n",
    "    print(f\"Analysis summary saved to: {summary_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Updated paths for SSP 8.5 ensemble\n",
    "    input_dir = Path(r\"D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\")\n",
    "    output_dir = Path(r\"D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\")\n",
    "    basin_shapefile = Path(r\"D:\\RICAAR\\surfacebasin\\surface_basin.shp\")\n",
    "    gov_shapefile = Path(r\"D:\\RICAAR\\Governorates\\JordanwithGovernorates.shp\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"SSP 8.5 ENSEMBLE PRECIPITATION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"Basin shapefile: {basin_shapefile}\")\n",
    "    print(f\"Jordan shapefile: {gov_shapefile}\")\n",
    "    \n",
    "    try:\n",
    "        saved_files = process_precipitation_data(\n",
    "            input_dir,\n",
    "            output_dir,\n",
    "            basin_shapefile,\n",
    "            gov_shapefile\n",
    "        )\n",
    "        \n",
    "        if saved_files:\n",
    "            create_analysis_summary(output_dir, saved_files)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PROCESSING SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Successfully processed SSP 8.5 ensemble data\")\n",
    "        print(f\"Files created: {len(saved_files) if saved_files else 0}\")\n",
    "        print(f\"Output location: {output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during processing: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "    \n",
    "    print(\"\\nSSP 8.5 ensemble seasonal analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57477e80-3202-434b-a171-8eaa4f135914",
   "metadata": {},
   "source": [
    "## convert to excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c50510-f841-45e0-b9a4-aa08ae2027ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SSP 8.5 ENSEMBLE NETCDF TO EXCEL CONVERTER\n",
      "======================================================================\n",
      "Input directory:  D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\n",
      "Output directory: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\n",
      "\n",
      "Starting SSP 8.5 NetCDF to Excel conversion...\n",
      "Found 8 NetCDF files to process\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_far_future_dry_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_far_future_dry_season_mmpermonth.xlsx\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_far_future_wet_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_far_future_wet_season_mmpermonth.xlsx\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_mid_future_dry_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_mid_future_dry_season_mmpermonth.xlsx\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_mid_future_wet_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_mid_future_wet_season_mmpermonth.xlsx\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_near_future_dry_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_near_future_dry_season_mmpermonth.xlsx\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_near_future_wet_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_near_future_wet_season_mmpermonth.xlsx\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_reference_dry_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_reference_dry_season_mmpermonth.xlsx\n",
      "\n",
      "Processing precipitation_ssp85_ensemble_reference_wet_season_mmpermonth.nc\n",
      "  Dataset shape: (85, 75)\n",
      "  Coordinate ranges - Lat: 27.050 to 35.450\n",
      "  Coordinate ranges - Lon: 33.550 to 40.950\n",
      "  Valid data points: 824/6375 (12.9%)\n",
      "  Saved D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\precipitation_ssp85_ensemble_reference_wet_season_mmpermonth.xlsx\n",
      "\n",
      "Conversion summary saved to: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\SSP85_Conversion_Summary.xlsx\n",
      "\n",
      "Creating master comparison summary...\n",
      "Master summary saved to: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\\SSP85_Master_Summary.xlsx\n",
      "\n",
      "======================================================================\n",
      "CONVERSION SUMMARY\n",
      "======================================================================\n",
      "Total files processed: 8\n",
      "Successfully converted: 8\n",
      "Failed conversions: 0\n",
      "\n",
      "Excel files created in: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\n",
      "\n",
      "Files created:\n",
      "  - precipitation_ssp85_ensemble_far_future_dry_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 2061-2070, Season: dry\n",
      "    Mean: 2.53 mm/month, Max: 4.99 mm/month\n",
      "  - precipitation_ssp85_ensemble_far_future_wet_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 2061-2070, Season: wet\n",
      "    Mean: 17.64 mm/month, Max: 57.82 mm/month\n",
      "  - precipitation_ssp85_ensemble_mid_future_dry_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 2041-2060, Season: dry\n",
      "    Mean: 2.46 mm/month, Max: 5.05 mm/month\n",
      "  - precipitation_ssp85_ensemble_mid_future_wet_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 2041-2060, Season: wet\n",
      "    Mean: 16.69 mm/month, Max: 60.90 mm/month\n",
      "  - precipitation_ssp85_ensemble_near_future_dry_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 2021-2040, Season: dry\n",
      "    Mean: 2.09 mm/month, Max: 5.04 mm/month\n",
      "  - precipitation_ssp85_ensemble_near_future_wet_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 2021-2040, Season: wet\n",
      "    Mean: 16.56 mm/month, Max: 65.84 mm/month\n",
      "  - precipitation_ssp85_ensemble_reference_dry_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 1995-2014, Season: dry\n",
      "    Mean: 2.15 mm/month, Max: 5.21 mm/month\n",
      "  - precipitation_ssp85_ensemble_reference_wet_season_mmpermonth.xlsx (824 data points)\n",
      "    Period: 1995-2014, Season: wet\n",
      "    Mean: 16.31 mm/month, Max: 68.69 mm/month\n",
      "\n",
      "SSP 8.5 NetCDF to Excel conversion complete!\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_nc_to_excel(nc_dir, excel_dir):\n",
    "    \"\"\"Convert NetCDF files to Excel format with data and summary sheets\"\"\"\n",
    "    print(\"\\nStarting SSP 8.5 NetCDF to Excel conversion...\")\n",
    "    \n",
    "    # Create Excel output directory\n",
    "    excel_dir = Path(excel_dir)\n",
    "    excel_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Process each NC file - updated pattern for SSP 8.5 ensemble files\n",
    "    nc_files = list(Path(nc_dir).glob(\"precipitation_ssp85_ensemble_*_season_mmpermonth.nc\"))\n",
    "    print(f\"Found {len(nc_files)} NetCDF files to process\")\n",
    "    \n",
    "    if not nc_files:\n",
    "        print(\"No SSP 8.5 ensemble files found. Checking for any precipitation files...\")\n",
    "        nc_files = list(Path(nc_dir).glob(\"precipitation_*.nc\"))\n",
    "        print(f\"Found {len(nc_files)} total precipitation files\")\n",
    "    \n",
    "    conversion_summary = []\n",
    "    \n",
    "    for nc_file in nc_files:\n",
    "        print(f\"\\nProcessing {nc_file.name}\")\n",
    "        try:\n",
    "            # Read NetCDF file\n",
    "            with xr.open_dataset(nc_file) as ds:\n",
    "                print(f\"  Dataset shape: {ds.prAdjust.shape}\")\n",
    "                print(f\"  Coordinate ranges - Lat: {ds.lat.min().values:.3f} to {ds.lat.max().values:.3f}\")\n",
    "                print(f\"  Coordinate ranges - Lon: {ds.lon.min().values:.3f} to {ds.lon.max().values:.3f}\")\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                df_data = []\n",
    "                total_points = len(ds.lat) * len(ds.lon)\n",
    "                valid_points = 0\n",
    "                \n",
    "                for lat in ds.lat.values:\n",
    "                    for lon in ds.lon.values:\n",
    "                        value = float(ds.prAdjust.sel(lat=lat, lon=lon).values)\n",
    "                        if not np.isnan(value) and value != 0:  # Include non-zero, non-NaN values\n",
    "                            df_data.append({\n",
    "                                'Latitude': lat,\n",
    "                                'Longitude': lon,\n",
    "                                'Precipitation (mm/month)': value\n",
    "                            })\n",
    "                            valid_points += 1\n",
    "                \n",
    "                print(f\"  Valid data points: {valid_points}/{total_points} ({valid_points/total_points*100:.1f}%)\")\n",
    "                \n",
    "                if df_data:\n",
    "                    # Create main data DataFrame\n",
    "                    df = pd.DataFrame(df_data)\n",
    "                    df = df.sort_values(['Latitude', 'Longitude'])\n",
    "                    \n",
    "                    # Extract metadata from file attributes if available\n",
    "                    metadata_info = {}\n",
    "                    if hasattr(ds, 'attrs'):\n",
    "                        for attr in ['scenario', 'period', 'season', 'source', 'description', 'models_used', 'ensemble_method']:\n",
    "                            if attr in ds.attrs:\n",
    "                                metadata_info[attr] = ds.attrs[attr]\n",
    "                    \n",
    "                    # Calculate summary statistics\n",
    "                    summary_data = {\n",
    "                        'Statistic': [\n",
    "                            'File Name',\n",
    "                            'Scenario',\n",
    "                            'Period',\n",
    "                            'Season',\n",
    "                            'Source',\n",
    "                            'Models Used',\n",
    "                            'Number of Valid Points',\n",
    "                            'Total Grid Points',\n",
    "                            'Data Coverage (%)',\n",
    "                            'Total Precipitation (mm/month)',\n",
    "                            'Mean Precipitation (mm/month)',\n",
    "                            'Median Precipitation (mm/month)',\n",
    "                            'Maximum Precipitation (mm/month)',\n",
    "                            'Minimum Precipitation (mm/month)',\n",
    "                            'Standard Deviation (mm/month)',\n",
    "                            'Latitude Range',\n",
    "                            'Longitude Range',\n",
    "                            'Processing Date'\n",
    "                        ],\n",
    "                        'Value': [\n",
    "                            nc_file.name,\n",
    "                            metadata_info.get('scenario', 'SSP 8.5'),\n",
    "                            metadata_info.get('period', 'Unknown'),\n",
    "                            metadata_info.get('season', 'Unknown'),\n",
    "                            metadata_info.get('source', '6-model ensemble average'),\n",
    "                            metadata_info.get('models_used', 'CMCC-CM2-SR5, CNRM-ESM2-1, EC-Earth3-Veg, IPSL-CM6A-LR, MPI-ESM1-2-LR, NorESM2-MM'),\n",
    "                            len(df),\n",
    "                            total_points,\n",
    "                            f\"{valid_points/total_points*100:.1f}%\",\n",
    "                            f\"{df['Precipitation (mm/month)'].sum():.2f}\",\n",
    "                            f\"{df['Precipitation (mm/month)'].mean():.2f}\",\n",
    "                            f\"{df['Precipitation (mm/month)'].median():.2f}\",\n",
    "                            f\"{df['Precipitation (mm/month)'].max():.2f}\",\n",
    "                            f\"{df['Precipitation (mm/month)'].min():.2f}\",\n",
    "                            f\"{df['Precipitation (mm/month)'].std():.2f}\",\n",
    "                            f\"{df['Latitude'].min():.4f}째N to {df['Latitude'].max():.4f}째N\",\n",
    "                            f\"{df['Longitude'].min():.4f}째E to {df['Longitude'].max():.4f}째E\",\n",
    "                            pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        ]\n",
    "                    }\n",
    "                    summary_df = pd.DataFrame(summary_data)\n",
    "                    \n",
    "                    # Create additional analysis sheet\n",
    "                    # Precipitation distribution analysis\n",
    "                    precip_values = df['Precipitation (mm/month)']\n",
    "                    percentiles = [5, 10, 25, 50, 75, 90, 95]\n",
    "                    \n",
    "                    distribution_data = {\n",
    "                        'Percentile': [f\"{p}th\" for p in percentiles],\n",
    "                        'Precipitation (mm/month)': [f\"{np.percentile(precip_values, p):.2f}\" for p in percentiles]\n",
    "                    }\n",
    "                    distribution_df = pd.DataFrame(distribution_data)\n",
    "                    \n",
    "                    # Create precipitation categories analysis\n",
    "                    categories = ['Very Low (0-10)', 'Low (10-50)', 'Moderate (50-100)', 'High (100-200)', 'Very High (200+)']\n",
    "                    category_counts = [\n",
    "                        sum((precip_values >= 0) & (precip_values < 10)),\n",
    "                        sum((precip_values >= 10) & (precip_values < 50)),\n",
    "                        sum((precip_values >= 50) & (precip_values < 100)),\n",
    "                        sum((precip_values >= 100) & (precip_values < 200)),\n",
    "                        sum(precip_values >= 200)\n",
    "                    ]\n",
    "                    \n",
    "                    category_data = {\n",
    "                        'Precipitation Category (mm/month)': categories,\n",
    "                        'Number of Grid Points': category_counts,\n",
    "                        'Percentage': [f\"{count/len(precip_values)*100:.1f}%\" for count in category_counts]\n",
    "                    }\n",
    "                    category_df = pd.DataFrame(category_data)\n",
    "                    \n",
    "                    # Save to Excel with multiple sheets\n",
    "                    excel_file = excel_dir / f\"{nc_file.stem}.xlsx\"\n",
    "                    with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "                        # Main data sheet\n",
    "                        df.to_excel(writer, sheet_name='Precipitation_Data', index=False)\n",
    "                        \n",
    "                        # Summary statistics sheet\n",
    "                        summary_df.to_excel(writer, sheet_name='Summary_Statistics', index=False)\n",
    "                        \n",
    "                        # Distribution analysis sheet\n",
    "                        distribution_df.to_excel(writer, sheet_name='Distribution_Analysis', index=False)\n",
    "                        \n",
    "                        # Category analysis sheet\n",
    "                        category_df.to_excel(writer, sheet_name='Category_Analysis', index=False)\n",
    "                        \n",
    "                        # Metadata sheet (if available)\n",
    "                        if metadata_info:\n",
    "                            metadata_df = pd.DataFrame(list(metadata_info.items()), \n",
    "                                                     columns=['Attribute', 'Value'])\n",
    "                            metadata_df.to_excel(writer, sheet_name='Metadata', index=False)\n",
    "                    \n",
    "                    print(f\"  Saved {excel_file}\")\n",
    "                    \n",
    "                    # Add to conversion summary\n",
    "                    conversion_summary.append({\n",
    "                        'NetCDF_File': nc_file.name,\n",
    "                        'Excel_File': excel_file.name,\n",
    "                        'Scenario': metadata_info.get('scenario', 'SSP 8.5'),\n",
    "                        'Period': metadata_info.get('period', 'Unknown'),\n",
    "                        'Season': metadata_info.get('season', 'Unknown'),\n",
    "                        'Valid_Points': valid_points,\n",
    "                        'Total_Points': total_points,\n",
    "                        'Coverage_Percent': f\"{valid_points/total_points*100:.1f}%\",\n",
    "                        'Mean_Precipitation': f\"{df['Precipitation (mm/month)'].mean():.2f}\",\n",
    "                        'Max_Precipitation': f\"{df['Precipitation (mm/month)'].max():.2f}\",\n",
    "                        'Status': 'Success'\n",
    "                    })\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  Warning: No valid data points found in {nc_file.name}\")\n",
    "                    conversion_summary.append({\n",
    "                        'NetCDF_File': nc_file.name,\n",
    "                        'Excel_File': 'Not created',\n",
    "                        'Scenario': 'SSP 8.5',\n",
    "                        'Period': 'Unknown',\n",
    "                        'Season': 'Unknown',\n",
    "                        'Valid_Points': 0,\n",
    "                        'Total_Points': total_points,\n",
    "                        'Coverage_Percent': '0.0%',\n",
    "                        'Mean_Precipitation': 'N/A',\n",
    "                        'Max_Precipitation': 'N/A',\n",
    "                        'Status': 'No valid data'\n",
    "                    })\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {nc_file.name}: {str(e)}\")\n",
    "            conversion_summary.append({\n",
    "                'NetCDF_File': nc_file.name,\n",
    "                'Excel_File': 'Error',\n",
    "                'Scenario': 'SSP 8.5',\n",
    "                'Period': 'Error',\n",
    "                'Season': 'Error',\n",
    "                'Valid_Points': 'Error',\n",
    "                'Total_Points': 'Error',\n",
    "                'Coverage_Percent': 'Error',\n",
    "                'Mean_Precipitation': 'Error',\n",
    "                'Max_Precipitation': 'Error',\n",
    "                'Status': f'Error: {str(e)}'\n",
    "            })\n",
    "    \n",
    "    # Save conversion summary\n",
    "    if conversion_summary:\n",
    "        summary_df = pd.DataFrame(conversion_summary)\n",
    "        summary_file = excel_dir / \"SSP85_Conversion_Summary.xlsx\"\n",
    "        summary_df.to_excel(summary_file, index=False)\n",
    "        print(f\"\\nConversion summary saved to: {summary_file}\")\n",
    "    \n",
    "    return conversion_summary\n",
    "\n",
    "def create_master_summary(excel_dir, conversion_summary):\n",
    "    \"\"\"Create a master summary comparing all periods and seasons\"\"\"\n",
    "    if not conversion_summary or not any(item['Status'] == 'Success' for item in conversion_summary):\n",
    "        return\n",
    "    \n",
    "    print(\"\\nCreating master comparison summary...\")\n",
    "    \n",
    "    # Filter successful conversions\n",
    "    successful = [item for item in conversion_summary if item['Status'] == 'Success']\n",
    "    \n",
    "    if len(successful) > 0:\n",
    "        comparison_data = []\n",
    "        for item in successful:\n",
    "            comparison_data.append({\n",
    "                'Period': item['Period'],\n",
    "                'Season': item['Season'],\n",
    "                'File_Name': item['Excel_File'],\n",
    "                'Valid_Points': item['Valid_Points'],\n",
    "                'Coverage_%': item['Coverage_Percent'],\n",
    "                'Mean_Precipitation_mm_month': float(item['Mean_Precipitation']),\n",
    "                'Max_Precipitation_mm_month': float(item['Max_Precipitation'])\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        # Create summary by period\n",
    "        period_summary = comparison_df.groupby('Period').agg({\n",
    "            'Mean_Precipitation_mm_month': 'mean',\n",
    "            'Max_Precipitation_mm_month': 'max',\n",
    "            'Valid_Points': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        # Create summary by season\n",
    "        season_summary = comparison_df.groupby('Season').agg({\n",
    "            'Mean_Precipitation_mm_month': 'mean',\n",
    "            'Max_Precipitation_mm_month': 'max',\n",
    "            'Valid_Points': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        # Save master summary\n",
    "        master_file = excel_dir / \"SSP85_Master_Summary.xlsx\"\n",
    "        with pd.ExcelWriter(master_file, engine='openpyxl') as writer:\n",
    "            comparison_df.to_excel(writer, sheet_name='All_Files_Comparison', index=False)\n",
    "            period_summary.to_excel(writer, sheet_name='Period_Summary')\n",
    "            season_summary.to_excel(writer, sheet_name='Season_Summary')\n",
    "        \n",
    "        print(f\"Master summary saved to: {master_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to convert SSP 8.5 NetCDF files to Excel\"\"\"\n",
    "    # Define paths for SSP 8.5 ensemble\n",
    "    nc_dir = Path(r\"D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\")\n",
    "    excel_dir = Path(r\"D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model8.5\\ensemble.6models\\nc.files\\difference.files\\Excel_files\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SSP 8.5 ENSEMBLE NETCDF TO EXCEL CONVERTER\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Input directory:  {nc_dir}\")\n",
    "    print(f\"Output directory: {excel_dir}\")\n",
    "    \n",
    "    # Check if input directory exists\n",
    "    if not nc_dir.exists():\n",
    "        print(f\"\\nError: Input directory does not exist: {nc_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Convert files\n",
    "    conversion_summary = convert_nc_to_excel(nc_dir, excel_dir)\n",
    "    \n",
    "    # Create master summary\n",
    "    if conversion_summary:\n",
    "        create_master_summary(excel_dir, conversion_summary)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONVERSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if conversion_summary:\n",
    "        successful = sum(1 for item in conversion_summary if item['Status'] == 'Success')\n",
    "        failed = len(conversion_summary) - successful\n",
    "        \n",
    "        print(f\"Total files processed: {len(conversion_summary)}\")\n",
    "        print(f\"Successfully converted: {successful}\")\n",
    "        print(f\"Failed conversions: {failed}\")\n",
    "        \n",
    "        if successful > 0:\n",
    "            print(f\"\\nExcel files created in: {excel_dir}\")\n",
    "            print(\"\\nFiles created:\")\n",
    "            for item in conversion_summary:\n",
    "                if item['Status'] == 'Success':\n",
    "                    print(f\"  - {item['Excel_File']} ({item['Valid_Points']} data points)\")\n",
    "                    print(f\"    Period: {item['Period']}, Season: {item['Season']}\")\n",
    "                    print(f\"    Mean: {item['Mean_Precipitation']} mm/month, Max: {item['Max_Precipitation']} mm/month\")\n",
    "        \n",
    "        if failed > 0:\n",
    "            print(f\"\\nFailed files:\")\n",
    "            for item in conversion_summary:\n",
    "                if item['Status'] != 'Success':\n",
    "                    print(f\"  - {item['NetCDF_File']}: {item['Status']}\")\n",
    "    else:\n",
    "        print(\"No files were processed.\")\n",
    "    \n",
    "    print(\"\\nSSP 8.5 NetCDF to Excel conversion complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff9f2d-560a-4ef3-98ed-80e61b97f36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
