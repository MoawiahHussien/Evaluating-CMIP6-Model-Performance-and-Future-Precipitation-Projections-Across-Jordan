{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96777c55-462a-4434-a8b4-a570e338e95c",
   "metadata": {},
   "source": [
    "## Excel sheet structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a2a29b-81c9-44b7-a094-0a68cf1e8e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in stations file:\n",
      "['STATION_ID', 'STATION_NAME', 'PALESTINE_NORTH', 'PALESTINE_EAST', 'Longitude', 'Latitude', 'ELEVATION', 'TYPE', 'BASIN', 'PERIOD', 'NOTE']\n",
      "\n",
      "First few rows of the data:\n",
      "  STATION_ID                     STATION_NAME  PALESTINE_NORTH  \\\n",
      "0     H 0001          H4 EVAP.ST (METEO DEPT)          1216000   \n",
      "1     H 0003                  KH.UM RUJEIM TO          1228800   \n",
      "2     H 0002                      TARABEEL TO          1237899   \n",
      "3     F 0007                      AL-WISAD TO          1144800   \n",
      "4     AD0032  BAQURA MET.STATION (METEO DEPT)          1224300   \n",
      "\n",
      "   PALESTINE_EAST  Longitude   Latitude  ELEVATION    TYPE         BASIN  \\\n",
      "0          450500  38.195443  32.502641      755.0   DAILY        HAMMAD   \n",
      "1          486800  38.585841  32.608084        NaN  ANNAUL        HAMMAD   \n",
      "2          508491  38.820090  32.683531        NaN  ANNAUL        HAMMAD   \n",
      "3          435000  38.010807  31.865164      700.0   DAILY        HAMMAD   \n",
      "4          206300  35.596982  32.612437     -205.0   DAILY  JORDAN VALLY   \n",
      "\n",
      "      PERIOD NOTE  \n",
      "0  1971-2014  NaN  \n",
      "1  1971-2014  NaN  \n",
      "2  1971-2014  NaN  \n",
      "3  1971-2014  NaN  \n",
      "4  1971-2014  NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# First, let's look at the structure of the stations file\n",
    "stations_file = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\OBSERVATIONS\\Selected.Pr.Stations.locations.xlsx\"\n",
    "stations_df = pd.read_excel(stations_file)\n",
    "\n",
    "# Print column names to see what we're working with\n",
    "print(\"Columns in stations file:\")\n",
    "print(stations_df.columns.tolist())\n",
    "print(\"\\nFirst few rows of the data:\")\n",
    "print(stations_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2211b49-5bf4-4994-8e48-16d37876a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: CMCC-CM2-SR5\n",
      "Processing model: CNRM-ESM2-1\n",
      "Processing model: EC-Earth3-Veg\n",
      "Processing model: IPSL-CM6A-LR\n",
      "Processing model: NorESM2-MM\n",
      "Processing model: MPI-ESM1-2-LR\n",
      "\n",
      "Results saved to: D:\\RICAAR\\Pr.New.Stations.Selection\\validation.according.to.basin.2\n",
      "\n",
      "Files created:\n",
      "- CMCC-CM2-SR5_Basin_Validation.xlsx\n",
      "- CNRM-ESM2-1_Basin_Validation.xlsx\n",
      "- EC-Earth3-Veg_Basin_Validation.xlsx\n",
      "- IPSL-CM6A-LR_Basin_Validation.xlsx\n",
      "- NorESM2-MM_Basin_Validation.xlsx\n",
      "- MPI-ESM1-2-LR_Basin_Validation.xlsx\n",
      "- Overall_Basin_Comparison.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "base_path = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\validation_results3\"\n",
    "stations_file = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\OBSERVATIONS\\Selected.Pr.Stations.locations.xlsx\"\n",
    "output_dir = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\validation.according.to.basin.2\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List of models\n",
    "models = [\n",
    "    'CMCC-CM2-SR5',\n",
    "    'CNRM-ESM2-1',\n",
    "    'EC-Earth3-Veg',\n",
    "    'IPSL-CM6A-LR',\n",
    "    'NorESM2-MM',\n",
    "    'MPI-ESM1-2-LR'\n",
    "]\n",
    "\n",
    "# Read stations and their basin information\n",
    "stations_df = pd.read_excel(stations_file)\n",
    "\n",
    "def process_model_data(model_name):\n",
    "    \"\"\"Process validation metrics for a single model\"\"\"\n",
    "    model_path = os.path.join(base_path, model_name, \"validation_heatmaps\")\n",
    "    \n",
    "    # Read all metrics\n",
    "    metrics = {}\n",
    "    for metric in ['r', 'NSE', 'PBIAS', 'RMSE', 'MAE']:\n",
    "        file_path = os.path.join(model_path, f'{metric}_values.xlsx')\n",
    "        if os.path.exists(file_path):\n",
    "            metrics[metric] = pd.read_excel(file_path)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_basin_metrics(metrics, basin_stations):\n",
    "    \"\"\"Calculate average metrics for a basin\"\"\"\n",
    "    basin_metrics = {}\n",
    "    \n",
    "    for metric_name, metric_data in metrics.items():\n",
    "        # Convert Station_ID to match format in stations_df if needed\n",
    "        basin_values = metric_data[metric_data['Station_ID'].isin(basin_stations)]['Value']\n",
    "        \n",
    "        basin_metrics[f'{metric_name}_mean'] = basin_values.mean()\n",
    "        basin_metrics[f'{metric_name}_std'] = basin_values.std()\n",
    "        basin_metrics[f'{metric_name}_min'] = basin_values.min()\n",
    "        basin_metrics[f'{metric_name}_max'] = basin_values.max()\n",
    "        basin_metrics[f'{metric_name}_count'] = len(basin_values)\n",
    "    \n",
    "    return basin_metrics\n",
    "\n",
    "# Process all models\n",
    "results = {}\n",
    "for model in models:\n",
    "    print(f\"Processing model: {model}\")\n",
    "    \n",
    "    # Get model metrics\n",
    "    model_metrics = process_model_data(model)\n",
    "    \n",
    "    # Create detailed results for each basin\n",
    "    basin_results = {}\n",
    "    basin_summaries = []\n",
    "    \n",
    "    for basin in stations_df['BASIN'].unique():\n",
    "        # Get stations for this basin\n",
    "        basin_stations = stations_df[stations_df['BASIN'] == basin]['STATION_ID'].tolist()\n",
    "        \n",
    "        # Get detailed station data for this basin\n",
    "        basin_detail = pd.DataFrame()\n",
    "        for metric, data in model_metrics.items():\n",
    "            basin_data = data[data['Station_ID'].isin(basin_stations)]\n",
    "            if len(basin_detail) == 0:\n",
    "                basin_detail['Station_ID'] = basin_data['Station_ID']\n",
    "                basin_detail['Station_Name'] = basin_data['Station_Name']\n",
    "            basin_detail[f'{metric}'] = basin_data['Value']\n",
    "        \n",
    "        if not basin_detail.empty:  # Only add if we have data for this basin\n",
    "            basin_results[basin] = basin_detail\n",
    "            \n",
    "            # Calculate basin summary metrics\n",
    "            summary = calculate_basin_metrics(model_metrics, basin_stations)\n",
    "            summary['Basin'] = basin\n",
    "            basin_summaries.append(summary)\n",
    "    \n",
    "    results[model] = {\n",
    "        'basin_details': basin_results,\n",
    "        'basin_summary': pd.DataFrame(basin_summaries)\n",
    "    }\n",
    "\n",
    "# Save results for each model separately\n",
    "for model in results:\n",
    "    model_output_file = os.path.join(output_dir, f'{model}_Basin_Validation.xlsx')\n",
    "    with pd.ExcelWriter(model_output_file) as writer:\n",
    "        # Save basin details\n",
    "        for basin, data in results[model]['basin_details'].items():\n",
    "            sheet_name = f\"{basin[:31]}\"  # Excel sheet names limited to 31 chars\n",
    "            data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Save basin summary\n",
    "        results[model]['basin_summary'].to_excel(writer, sheet_name='Basin_Summary', index=False)\n",
    "\n",
    "# Create and save overall comparison\n",
    "overall_comparison = []\n",
    "for model in results:\n",
    "    model_summary = results[model]['basin_summary'].copy()\n",
    "    model_summary['Model'] = model\n",
    "    overall_comparison.append(model_summary)\n",
    "\n",
    "overall_df = pd.concat(overall_comparison, ignore_index=True)\n",
    "overall_df.to_excel(os.path.join(output_dir, 'Overall_Basin_Comparison.xlsx'), index=False)\n",
    "\n",
    "print(\"\\nResults saved to:\", output_dir)\n",
    "print(\"\\nFiles created:\")\n",
    "for model in models:\n",
    "    print(f\"- {model}_Basin_Validation.xlsx\")\n",
    "print(\"- Overall_Basin_Comparison.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eddec6-a2e4-4954-aee5-2577c5073ca8",
   "metadata": {},
   "source": [
    "## the above code worked but the below is a modification to eleminate some stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92f045a-0d12-4c67-ab58-5f9c2bdef270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: CMCC-CM2-SR5\n",
      "Processing model: CNRM-ESM2-1\n",
      "Processing model: EC-Earth3-Veg\n",
      "Processing model: IPSL-CM6A-LR\n",
      "Processing model: NorESM2-MM\n",
      "Processing model: MPI-ESM1-2-LR\n",
      "\n",
      "Excluded stations:\n",
      "\n",
      "Results saved to: D:\\RICAAR\\Pr.New.Stations.Selection\\validation.according.to.basin.2\n",
      "\n",
      "Files created:\n",
      "- CMCC-CM2-SR5_Basin_Validation.xlsx\n",
      "- CNRM-ESM2-1_Basin_Validation.xlsx\n",
      "- EC-Earth3-Veg_Basin_Validation.xlsx\n",
      "- IPSL-CM6A-LR_Basin_Validation.xlsx\n",
      "- NorESM2-MM_Basin_Validation.xlsx\n",
      "- MPI-ESM1-2-LR_Basin_Validation.xlsx\n",
      "- Overall_Basin_Comparison.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "base_path = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\validation_results3\"\n",
    "stations_file = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\OBSERVATIONS\\Selected.Pr.Stations.locations.xlsx\"\n",
    "output_dir = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\validation.according.to.basin.2\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List of models\n",
    "models = [\n",
    "    'CMCC-CM2-SR5',\n",
    "    'CNRM-ESM2-1',\n",
    "    'EC-Earth3-Veg',\n",
    "    'IPSL-CM6A-LR',\n",
    "    'NorESM2-MM',\n",
    "    'MPI-ESM1-2-LR'\n",
    "]\n",
    "\n",
    "# Stations to exclude\n",
    "excluded_stations = ['F 0007', 'DA0007', 'CF0008', 'ED0004', 'ED0012']\n",
    "\n",
    "# Read stations and their basin information\n",
    "stations_df = pd.read_excel(stations_file)\n",
    "# Remove excluded stations\n",
    "stations_df = stations_df[~stations_df['STATION_ID'].isin(excluded_stations)]\n",
    "\n",
    "def process_model_data(model_name):\n",
    "    \"\"\"Process validation metrics for a single model\"\"\"\n",
    "    model_path = os.path.join(base_path, model_name, \"validation_heatmaps\")\n",
    "    \n",
    "    # Read all metrics\n",
    "    metrics = {}\n",
    "    for metric in ['r', 'NSE', 'PBIAS', 'RMSE', 'MAE']:\n",
    "        file_path = os.path.join(model_path, f'{metric}_values.xlsx')\n",
    "        if os.path.exists(file_path):\n",
    "            metrics[metric] = pd.read_excel(file_path)\n",
    "            # Remove excluded stations from metrics data\n",
    "            metrics[metric] = metrics[metric][~metrics[metric]['Station_ID'].isin(excluded_stations)]\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_basin_metrics(metrics, basin_stations):\n",
    "    \"\"\"Calculate average metrics for a basin\"\"\"\n",
    "    basin_metrics = {}\n",
    "    \n",
    "    for metric_name, metric_data in metrics.items():\n",
    "        basin_values = metric_data[metric_data['Station_ID'].isin(basin_stations)]['Value']\n",
    "        \n",
    "        basin_metrics[f'{metric_name}_mean'] = basin_values.mean()\n",
    "        basin_metrics[f'{metric_name}_std'] = basin_values.std()\n",
    "        basin_metrics[f'{metric_name}_min'] = basin_values.min()\n",
    "        basin_metrics[f'{metric_name}_max'] = basin_values.max()\n",
    "        basin_metrics[f'{metric_name}_count'] = len(basin_values)\n",
    "    \n",
    "    return basin_metrics\n",
    "\n",
    "# Process all models\n",
    "results = {}\n",
    "for model in models:\n",
    "    print(f\"Processing model: {model}\")\n",
    "    \n",
    "    # Get model metrics\n",
    "    model_metrics = process_model_data(model)\n",
    "    \n",
    "    # Create detailed results for each basin\n",
    "    basin_results = {}\n",
    "    basin_summaries = []\n",
    "    \n",
    "    for basin in stations_df['BASIN'].unique():\n",
    "        # Get stations for this basin\n",
    "        basin_stations = stations_df[stations_df['BASIN'] == basin]['STATION_ID'].tolist()\n",
    "        \n",
    "        # Get detailed station data for this basin\n",
    "        basin_detail = pd.DataFrame()\n",
    "        for metric, data in model_metrics.items():\n",
    "            basin_data = data[data['Station_ID'].isin(basin_stations)]\n",
    "            if len(basin_detail) == 0:\n",
    "                basin_detail['Station_ID'] = basin_data['Station_ID']\n",
    "                basin_detail['Station_Name'] = basin_data['Station_Name']\n",
    "            basin_detail[f'{metric}'] = basin_data['Value']\n",
    "        \n",
    "        if not basin_detail.empty:  # Only add if we have data for this basin\n",
    "            basin_results[basin] = basin_detail\n",
    "            \n",
    "            # Calculate basin summary metrics\n",
    "            summary = calculate_basin_metrics(model_metrics, basin_stations)\n",
    "            summary['Basin'] = basin\n",
    "            basin_summaries.append(summary)\n",
    "    \n",
    "    results[model] = {\n",
    "        'basin_details': basin_results,\n",
    "        'basin_summary': pd.DataFrame(basin_summaries)\n",
    "    }\n",
    "\n",
    "# Save results for each model separately\n",
    "for model in results:\n",
    "    model_output_file = os.path.join(output_dir, f'{model}_Basin_Validation.xlsx')\n",
    "    with pd.ExcelWriter(model_output_file) as writer:\n",
    "        # Save basin details\n",
    "        for basin, data in results[model]['basin_details'].items():\n",
    "            sheet_name = f\"{basin[:31]}\"  # Excel sheet names limited to 31 chars\n",
    "            data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # Save basin summary\n",
    "        results[model]['basin_summary'].to_excel(writer, sheet_name='Basin_Summary', index=False)\n",
    "\n",
    "# Create and save overall comparison\n",
    "overall_comparison = []\n",
    "for model in results:\n",
    "    model_summary = results[model]['basin_summary'].copy()\n",
    "    model_summary['Model'] = model\n",
    "    overall_comparison.append(model_summary)\n",
    "\n",
    "overall_df = pd.concat(overall_comparison, ignore_index=True)\n",
    "overall_df.to_excel(os.path.join(output_dir, 'Overall_Basin_Comparison.xlsx'), index=False)\n",
    "\n",
    "# Print summary of excluded stations\n",
    "print(\"\\nExcluded stations:\")\n",
    "for station in excluded_stations:\n",
    "    station_info = stations_df[stations_df['STATION_ID'] == station]\n",
    "    if not station_info.empty:\n",
    "        print(f\"- {station}: {station_info['BASIN'].iloc[0]} basin\")\n",
    "\n",
    "print(\"\\nResults saved to:\", output_dir)\n",
    "print(\"\\nFiles created:\")\n",
    "for model in models:\n",
    "    print(f\"- {model}_Basin_Validation.xlsx\")\n",
    "print(\"- Overall_Basin_Comparison.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37aecc-9f96-455c-9096-2555753a2c04",
   "metadata": {},
   "source": [
    "## best model for basins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84cfb13-dda4-4159-b71e-60b9e3ab870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model for Each Basin:\n",
      "==================================================\n",
      "\n",
      "Basin: HAMMAD\n",
      "Best Model: MPI-ESM1-2-LR\n",
      "Performance Metrics:\n",
      "  R-value: 0.926\n",
      "  NSE: -0.657\n",
      "  PBIAS: 9.603%\n",
      "  RMSE: 3.294\n",
      "  MAE: 2.732\n",
      "  Average Rank: 1.20\n",
      "\n",
      "Basin: JORDAN VALLY\n",
      "Best Model: CNRM-ESM2-1\n",
      "Performance Metrics:\n",
      "  R-value: 0.976\n",
      "  NSE: 0.724\n",
      "  PBIAS: 16.097%\n",
      "  RMSE: 12.159\n",
      "  MAE: 10.505\n",
      "  Average Rank: 1.60\n",
      "\n",
      "Basin: N.R.S.W\n",
      "Best Model: NorESM2-MM\n",
      "Performance Metrics:\n",
      "  R-value: 0.991\n",
      "  NSE: 0.835\n",
      "  PBIAS: -14.528%\n",
      "  RMSE: 14.759\n",
      "  MAE: 12.635\n",
      "  Average Rank: 1.00\n",
      "\n",
      "Basin: YARMOUK\n",
      "Best Model: CNRM-ESM2-1\n",
      "Performance Metrics:\n",
      "  R-value: 0.951\n",
      "  NSE: 0.646\n",
      "  PBIAS: 7.589%\n",
      "  RMSE: 10.105\n",
      "  MAE: 7.737\n",
      "  Average Rank: 1.80\n",
      "\n",
      "Basin: AMMAN ZARQA\n",
      "Best Model: CMCC-CM2-SR5\n",
      "Performance Metrics:\n",
      "  R-value: 0.973\n",
      "  NSE: 0.454\n",
      "  PBIAS: 1.922%\n",
      "  RMSE: 14.644\n",
      "  MAE: 11.844\n",
      "  Average Rank: 2.00\n",
      "\n",
      "Basin: MUJIB\n",
      "Best Model: CMCC-CM2-SR5\n",
      "Performance Metrics:\n",
      "  R-value: 0.953\n",
      "  NSE: 0.159\n",
      "  PBIAS: 0.184%\n",
      "  RMSE: 10.698\n",
      "  MAE: 9.047\n",
      "  Average Rank: 1.60\n",
      "\n",
      "Basin: AZRAQ\n",
      "Best Model: MPI-ESM1-2-LR\n",
      "Performance Metrics:\n",
      "  R-value: 0.771\n",
      "  NSE: -2.063\n",
      "  PBIAS: 20.401%\n",
      "  RMSE: 5.304\n",
      "  MAE: 4.176\n",
      "  Average Rank: 1.60\n",
      "\n",
      "Basin: S.R.S.W\n",
      "Best Model: CMCC-CM2-SR5\n",
      "Performance Metrics:\n",
      "  R-value: 0.988\n",
      "  NSE: 0.608\n",
      "  PBIAS: -20.692%\n",
      "  RMSE: 21.086\n",
      "  MAE: 18.162\n",
      "  Average Rank: 1.60\n",
      "\n",
      "Basin: D.S.R.S.W\n",
      "Best Model: CMCC-CM2-SR5\n",
      "Performance Metrics:\n",
      "  R-value: 0.964\n",
      "  NSE: 0.638\n",
      "  PBIAS: -27.550%\n",
      "  RMSE: 14.736\n",
      "  MAE: 12.354\n",
      "  Average Rank: 1.60\n",
      "\n",
      "Basin: W.ARAB.NORTH\n",
      "Best Model: CMCC-CM2-SR5\n",
      "Performance Metrics:\n",
      "  R-value: 0.942\n",
      "  NSE: 0.454\n",
      "  PBIAS: -33.109%\n",
      "  RMSE: 12.761\n",
      "  MAE: 11.057\n",
      "  Average Rank: 1.80\n",
      "\n",
      "Basin: HASA\n",
      "Best Model: CMCC-CM2-SR5\n",
      "Performance Metrics:\n",
      "  R-value: 0.978\n",
      "  NSE: 0.591\n",
      "  PBIAS: -32.114%\n",
      "  RMSE: 11.745\n",
      "  MAE: 9.928\n",
      "  Average Rank: 1.80\n",
      "\n",
      "Basin: JAFER\n",
      "Best Model: NorESM2-MM\n",
      "Performance Metrics:\n",
      "  R-value: 0.824\n",
      "  NSE: -0.361\n",
      "  PBIAS: -12.494%\n",
      "  RMSE: 7.766\n",
      "  MAE: 6.494\n",
      "  Average Rank: 2.20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Read the overall comparison file\n",
    "comparison_file = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\validation.according.to.basin.2\\Overall_Basin_Comparison.xlsx\"\n",
    "df = pd.read_excel(comparison_file)\n",
    "\n",
    "def rank_models_by_basin():\n",
    "    \"\"\"Rank models for each basin based on multiple criteria\"\"\"\n",
    "    \n",
    "    # Define which metrics are better when higher or lower\n",
    "    higher_better = ['r_mean', 'NSE_mean']\n",
    "    lower_better = ['RMSE_mean', 'MAE_mean', 'PBIAS_mean']  # Using absolute value for PBIAS\n",
    "    \n",
    "    # Add absolute PBIAS column\n",
    "    df['abs_PBIAS_mean'] = df['PBIAS_mean'].abs()\n",
    "    \n",
    "    # Create ranking dataframe\n",
    "    rankings = pd.DataFrame()\n",
    "    \n",
    "    for basin in df['Basin'].unique():\n",
    "        basin_data = df[df['Basin'] == basin].copy()\n",
    "        \n",
    "        # Rank for each metric (1 is best)\n",
    "        for metric in higher_better:\n",
    "            basin_data[f'{metric}_rank'] = basin_data[metric].rank(ascending=False)\n",
    "            \n",
    "        for metric in lower_better:\n",
    "            if metric == 'PBIAS_mean':\n",
    "                basin_data[f'{metric}_rank'] = basin_data['abs_PBIAS_mean'].rank()\n",
    "            else:\n",
    "                basin_data[f'{metric}_rank'] = basin_data[metric].rank()\n",
    "        \n",
    "        # Calculate average rank\n",
    "        rank_columns = [col for col in basin_data.columns if col.endswith('_rank')]\n",
    "        basin_data['avg_rank'] = basin_data[rank_columns].mean(axis=1)\n",
    "        \n",
    "        # Sort by average rank\n",
    "        basin_data = basin_data.sort_values('avg_rank')\n",
    "        \n",
    "        # Add to rankings\n",
    "        rankings = pd.concat([rankings, basin_data])\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "def create_performance_summary(rankings):\n",
    "    \"\"\"Create a detailed performance summary\"\"\"\n",
    "    \n",
    "    summary = []\n",
    "    \n",
    "    for basin in rankings['Basin'].unique():\n",
    "        basin_data = rankings[rankings['Basin'] == basin].copy()\n",
    "        \n",
    "        # Get best model\n",
    "        best_model = basin_data.iloc[0]\n",
    "        \n",
    "        summary.append({\n",
    "            'Basin': basin,\n",
    "            'Best_Model': best_model['Model'],\n",
    "            'r_value': best_model['r_mean'],\n",
    "            'NSE_value': best_model['NSE_mean'],\n",
    "            'PBIAS_value': best_model['PBIAS_mean'],\n",
    "            'RMSE_value': best_model['RMSE_mean'],\n",
    "            'MAE_value': best_model['MAE_mean'],\n",
    "            'Average_Rank': best_model['avg_rank']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "# Generate rankings and summary\n",
    "rankings = rank_models_by_basin()\n",
    "summary = create_performance_summary(rankings)\n",
    "\n",
    "# Save results\n",
    "output_dir = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\validation.according.to.basin.2\"\n",
    "rankings.to_excel(os.path.join(output_dir, 'Model_Rankings_by_Basin.xlsx'), index=False)\n",
    "summary.to_excel(os.path.join(output_dir, 'Best_Models_Summary.xlsx'), index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nBest Model for Each Basin:\")\n",
    "print(\"=\" * 50)\n",
    "for _, row in summary.iterrows():\n",
    "    print(f\"\\nBasin: {row['Basin']}\")\n",
    "    print(f\"Best Model: {row['Best_Model']}\")\n",
    "    print(f\"Performance Metrics:\")\n",
    "    print(f\"  R-value: {row['r_value']:.3f}\")\n",
    "    print(f\"  NSE: {row['NSE_value']:.3f}\")\n",
    "    print(f\"  PBIAS: {row['PBIAS_value']:.3f}%\")\n",
    "    print(f\"  RMSE: {row['RMSE_value']:.3f}\")\n",
    "    print(f\"  MAE: {row['MAE_value']:.3f}\")\n",
    "    print(f\"  Average Rank: {row['Average_Rank']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
