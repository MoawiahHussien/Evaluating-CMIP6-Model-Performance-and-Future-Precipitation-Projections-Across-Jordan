{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b673fc81-4bc5-4d94-bb74-06b04557d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "6-MODEL ENSEMBLE BASIN-BASED VALIDATION\n",
      "================================================================================\n",
      "üéØ Analyzing 6-model ensemble performance by basin\n",
      "üìä Using uniform 6-model ensemble approach\n",
      "üîç Following same methodology as 3-model ensemble validation\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Reading 6-model ensemble validation results...\n",
      "‚úÖ Loaded validation data for 49 stations\n",
      "üìä Model type: Ensemble_6Models\n",
      "üìç Reading station-basin mapping...\n",
      "‚úÖ Loaded basin mapping for 49 stations\n",
      "üìä Basins found: 12\n",
      "üìç Basin distribution:\n",
      "   - D.S.R.S.W: 7 stations\n",
      "   - AMMAN ZARQA (JORDAN): 6 stations\n",
      "   - MUJIB: 6 stations\n",
      "   - YARMOUK (JORDAN): 5 stations\n",
      "   - JAFER: 5 stations\n",
      "   - N.R.S.W: 4 stations\n",
      "   - AZRAQ (JORDAN): 4 stations\n",
      "   - S.R.S.W: 4 stations\n",
      "   - JORDAN VALLY (JORDAN): 3 stations\n",
      "   - W. ARABA NORTH: 3 stations\n",
      "   ... and 2 more basins\n",
      "üîó Merging validation data with basin information...\n",
      "‚úÖ Successfully merged data for 49 stations\n",
      "üìä Calculating basin-wise performance statistics...\n",
      "üèÜ Creating basin performance rankings...\n",
      "üíæ Saving results to: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\\ACCORDING.TO.BASIN\n",
      "üìä Found 3-model ensemble data - creating comparison...\n",
      "‚úÖ Ensemble comparison saved to: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\\ACCORDING.TO.BASIN\\Ensemble_Comparison_3vs6_Models.xlsx\n",
      "üìä Compared 49 common stations\n",
      "\n",
      "============================================================\n",
      "6-MODEL ENSEMBLE BASIN PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "Total basins analyzed: 12\n",
      "Total stations: 49\n",
      "Ensemble approach: Uniform 6-model ensemble\n",
      "\n",
      "üèÜ TOP 3 PERFORMING BASINS:\n",
      "----------------------------------------\n",
      "\n",
      "1. YARMOUK (JORDAN)\n",
      "   Stations: 5\n",
      "   Correlation: 0.961\n",
      "   NSE: 0.718\n",
      "   RMSE: 9.28\n",
      "   Category: Excellent\n",
      "   Overall Rank: 1\n",
      "\n",
      "2. HAMMAD\n",
      "   Stations: 1\n",
      "   Correlation: 0.881\n",
      "   NSE: -1.339\n",
      "   RMSE: 3.91\n",
      "   Category: Poor\n",
      "   Overall Rank: 2\n",
      "\n",
      "3. AMMAN ZARQA (JORDAN)\n",
      "   Stations: 6\n",
      "   Correlation: 0.976\n",
      "   NSE: 0.500\n",
      "   RMSE: 14.49\n",
      "   Category: Excellent\n",
      "   Overall Rank: 3\n",
      "\n",
      "üìä OVERALL ENSEMBLE STATISTICS:\n",
      "----------------------------------------\n",
      "Average Correlation: 0.937\n",
      "Average NSE: 0.050\n",
      "Average RMSE: 12.36\n",
      "Average Coverage: 0.667\n",
      "\n",
      "üèÖ PERFORMANCE CATEGORIES:\n",
      "----------------------------------------\n",
      "Excellent: 7 basins\n",
      "Poor: 3 basins\n",
      "Fair: 1 basins\n",
      "Good: 1 basins\n",
      "\n",
      "üéØ KEY INFORMATION:\n",
      "----------------------------------------\n",
      "‚úÖ Uniform 6-model ensemble applied to all basins\n",
      "üìä Models: CMCC-CM2-SR5, CNRM-ESM2-1, EC-Earth3-Veg, IPSL-CM6A-LR, MPI-ESM1-2-LR, NorESM2-MM\n",
      "üîç Results show ensemble performance across different hydrological regions\n",
      "üìà Basin-specific performance variations reflect regional climate model accuracy\n",
      "\n",
      "============================================================\n",
      "üéâ 6-MODEL ENSEMBLE BASIN-BASED VALIDATION COMPLETED!\n",
      "============================================================\n",
      "üìÅ Output directory: D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\\ACCORDING.TO.BASIN\n",
      "üìä Files created:\n",
      "   - Basin_Performance_Statistics_6Models.xlsx\n",
      "   - Basin_Detailed_Comparison_6Models.xlsx\n",
      "   - Basin_Performance_Rankings_6Models.xlsx\n",
      "   - Station_Basin_Validation_Data_6Models.xlsx\n",
      "   - Ensemble_6Models_Basin_Validation_Summary.xlsx (comprehensive)\n",
      "   - Generated_Station_Basin_Mapping.xlsx (if mapping was created)\n",
      "   - Ensemble_Comparison_3vs6_Models.xlsx (if 3-model data available)\n",
      "\n",
      "‚úÖ Uniform 6-model ensemble performance analyzed by basin\n",
      "üìä Ready for cross-ensemble performance comparison!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_basin_validation_analysis_6models():\n",
    "    \"\"\"Create basin-based validation analysis for 6-model ensemble\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"6-MODEL ENSEMBLE BASIN-BASED VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"üéØ Analyzing 6-model ensemble performance by basin\")\n",
    "    print(\"üìä Using uniform 6-model ensemble approach\")\n",
    "    print(\"üîç Following same methodology as 3-model ensemble validation\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Define paths\n",
    "    validation_results_file = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\\ensemble_6models_validation_results.xlsx\"\n",
    "    station_basin_mapping_file = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\OBSERVATIONS\\Station_Basin_Mapping.xlsx\"\n",
    "    output_dir = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.models.6.models\\validation_results\\ACCORDING.TO.BASIN\"\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if validation results file exists\n",
    "    if not os.path.exists(validation_results_file):\n",
    "        print(f\"‚ùå ERROR: Validation results file not found!\")\n",
    "        print(f\"Expected: {validation_results_file}\")\n",
    "        print(\"Please run the 6-model ensemble validation script first!\")\n",
    "        return\n",
    "    \n",
    "    # Read validation results\n",
    "    print(f\"üìä Reading 6-model ensemble validation results...\")\n",
    "    try:\n",
    "        validation_df = pd.read_excel(validation_results_file, sheet_name='Validation_Metrics')\n",
    "        print(f\"‚úÖ Loaded validation data for {len(validation_df)} stations\")\n",
    "        print(f\"üìä Model type: {validation_df['Model'].iloc[0] if len(validation_df) > 0 else 'Unknown'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading validation results: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if station-basin mapping exists\n",
    "    if not os.path.exists(station_basin_mapping_file):\n",
    "        print(f\"‚ùå ERROR: Station-basin mapping file not found!\")\n",
    "        print(f\"Expected: {station_basin_mapping_file}\")\n",
    "        print(\"Creating coordinate-based mapping as fallback...\")\n",
    "        \n",
    "        # Create coordinate-based mapping as fallback\n",
    "        basin_mapping = create_coordinate_based_mapping_6models(validation_df)\n",
    "        \n",
    "        # Save the mapping for future use\n",
    "        mapping_output_path = os.path.join(output_dir, \"Generated_Station_Basin_Mapping.xlsx\")\n",
    "        basin_mapping.to_excel(mapping_output_path, index=False)\n",
    "        print(f\"üíæ Saved generated mapping to: {mapping_output_path}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"üìç Reading station-basin mapping...\")\n",
    "        try:\n",
    "            basin_mapping = pd.read_excel(station_basin_mapping_file)\n",
    "            print(f\"‚úÖ Loaded basin mapping for {len(basin_mapping)} stations\")\n",
    "            print(f\"üìä Basins found: {basin_mapping['Basin'].nunique()}\")\n",
    "            \n",
    "            # Show basin distribution\n",
    "            basin_counts = basin_mapping['Basin'].value_counts()\n",
    "            print(f\"üìç Basin distribution:\")\n",
    "            for basin, count in basin_counts.head(10).items():\n",
    "                print(f\"   - {basin}: {count} stations\")\n",
    "            if len(basin_counts) > 10:\n",
    "                print(f\"   ... and {len(basin_counts) - 10} more basins\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading basin mapping: {e}\")\n",
    "            return\n",
    "    \n",
    "    # Merge validation data with basin information\n",
    "    print(f\"üîó Merging validation data with basin information...\")\n",
    "    \n",
    "    # Standardize station IDs for matching\n",
    "    validation_df['Station_ID_clean'] = validation_df['Station_ID'].str.strip().str.upper()\n",
    "    basin_mapping['Station_ID_clean'] = basin_mapping['Station_ID'].str.strip().str.upper()\n",
    "    \n",
    "    # Merge datasets\n",
    "    merged_df = pd.merge(validation_df, basin_mapping[['Station_ID_clean', 'Basin']], \n",
    "                        on='Station_ID_clean', how='left')\n",
    "    \n",
    "    # Check for stations without basin assignments\n",
    "    no_basin = merged_df[merged_df['Basin'].isna()]\n",
    "    if len(no_basin) > 0:\n",
    "        print(f\"‚ö†Ô∏è WARNING: {len(no_basin)} stations have no basin assignment:\")\n",
    "        for _, station in no_basin.iterrows():\n",
    "            print(f\"   - {station['Station_ID']}\")\n",
    "        \n",
    "        # Assign to 'Unknown' basin\n",
    "        merged_df['Basin'] = merged_df['Basin'].fillna('Unknown')\n",
    "    \n",
    "    print(f\"‚úÖ Successfully merged data for {len(merged_df)} stations\")\n",
    "    \n",
    "    # Calculate basin-wise statistics\n",
    "    print(f\"üìä Calculating basin-wise performance statistics...\")\n",
    "    \n",
    "    basin_stats = calculate_basin_statistics_6models(merged_df)\n",
    "    \n",
    "    # Create detailed basin comparison\n",
    "    basin_comparison = create_basin_comparison_6models(merged_df)\n",
    "    \n",
    "    # Create rankings and top performance analysis\n",
    "    print(f\"üèÜ Creating basin performance rankings...\")\n",
    "    rankings = rank_basins_by_performance_6models(basin_stats)\n",
    "    \n",
    "    # Save all results\n",
    "    print(f\"üíæ Saving results to: {output_dir}\")\n",
    "    \n",
    "    # Save individual files\n",
    "    basin_stats.to_excel(os.path.join(output_dir, 'Basin_Performance_Statistics_6Models.xlsx'), index=False)\n",
    "    basin_comparison.to_excel(os.path.join(output_dir, 'Basin_Detailed_Comparison_6Models.xlsx'), index=False)\n",
    "    rankings.to_excel(os.path.join(output_dir, 'Basin_Performance_Rankings_6Models.xlsx'), index=False)\n",
    "    merged_df.to_excel(os.path.join(output_dir, 'Station_Basin_Validation_Data_6Models.xlsx'), index=False)\n",
    "    \n",
    "    # Save comprehensive summary\n",
    "    save_comprehensive_summary_6models(basin_stats, basin_comparison, rankings, merged_df, output_dir)\n",
    "    \n",
    "    # Create comparison with 3-model ensemble if available\n",
    "    create_ensemble_comparison(merged_df, output_dir)\n",
    "    \n",
    "    # Print summary\n",
    "    print_basin_summary_6models(basin_stats, rankings)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"üéâ 6-MODEL ENSEMBLE BASIN-BASED VALIDATION COMPLETED!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    print(\"üìä Files created:\")\n",
    "    print(\"   - Basin_Performance_Statistics_6Models.xlsx\")\n",
    "    print(\"   - Basin_Detailed_Comparison_6Models.xlsx\") \n",
    "    print(\"   - Basin_Performance_Rankings_6Models.xlsx\")\n",
    "    print(\"   - Station_Basin_Validation_Data_6Models.xlsx\")\n",
    "    print(\"   - Ensemble_6Models_Basin_Validation_Summary.xlsx (comprehensive)\")\n",
    "    print(\"   - Generated_Station_Basin_Mapping.xlsx (if mapping was created)\")\n",
    "    print(\"   - Ensemble_Comparison_3vs6_Models.xlsx (if 3-model data available)\")\n",
    "    print(\"\\n‚úÖ Uniform 6-model ensemble performance analyzed by basin\")\n",
    "    print(\"üìä Ready for cross-ensemble performance comparison!\")\n",
    "\n",
    "def create_coordinate_based_mapping_6models(validation_df):\n",
    "    \"\"\"Create a coordinate-based basin mapping if mapping file doesn't exist\"\"\"\n",
    "    \n",
    "    print(\"üó∫Ô∏è Creating coordinate-based basin mapping for 6-model ensemble...\")\n",
    "    \n",
    "    # Simple coordinate-based basin assignment for Jordan\n",
    "    basin_mapping = []\n",
    "    \n",
    "    for _, station in validation_df.iterrows():\n",
    "        station_id = station['Station_ID']\n",
    "        lat = station.get('Latitude', 0)\n",
    "        lon = station.get('Longitude', 0)\n",
    "        \n",
    "        # Enhanced coordinate-based basin assignment for Jordan\n",
    "        if lat > 32.5:\n",
    "            if lon < 36.0:\n",
    "                basin = \"YARMOUK\"\n",
    "            else:\n",
    "                basin = \"JORDAN_VALLEY_NORTH\"\n",
    "        elif lat > 31.5:\n",
    "            if lon < 36.0:\n",
    "                basin = \"JORDAN_VALLEY_CENTRAL\"\n",
    "            else:\n",
    "                basin = \"EASTERN_BASIN\"\n",
    "        else:\n",
    "            if lon < 35.5:\n",
    "                basin = \"SOUTHERN_BASIN\"\n",
    "            else:\n",
    "                basin = \"DEAD_SEA_BASIN\"\n",
    "        \n",
    "        # Special handling for known problematic stations\n",
    "        if station_id in ['AD0023', 'AD0032']:\n",
    "            basin = f\"{basin}_BORDER\"  # Mark border stations\n",
    "        \n",
    "        basin_mapping.append({\n",
    "            'Station_ID': station_id,\n",
    "            'Basin': basin,\n",
    "            'Latitude': lat,\n",
    "            'Longitude': lon,\n",
    "            'Mapping_Method': 'Coordinate_Based_6Models',\n",
    "            'Notes': f'Generated for 6-model ensemble validation'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(basin_mapping)\n",
    "\n",
    "def calculate_basin_statistics_6models(merged_df):\n",
    "    \"\"\"Calculate comprehensive statistics for each basin - 6-model ensemble\"\"\"\n",
    "    \n",
    "    basin_stats = []\n",
    "    \n",
    "    for basin_name in merged_df['Basin'].unique():\n",
    "        basin_data = merged_df[merged_df['Basin'] == basin_name]\n",
    "        \n",
    "        # Calculate statistics for each metric\n",
    "        metrics = ['r', 'NSE', 'RMSE', 'MAE', 'PBIAS', 'Coverage_Ratio']\n",
    "        \n",
    "        basin_stat = {\n",
    "            'Basin': basin_name,\n",
    "            'Station_Count': len(basin_data),\n",
    "            'Model': 'Ensemble_6Models_Uniform',\n",
    "            'Ensemble_Type': '6_Models_Equal_Weight'\n",
    "        }\n",
    "        \n",
    "        for metric in metrics:\n",
    "            if metric in basin_data.columns:\n",
    "                valid_data = basin_data[metric].dropna()\n",
    "                if len(valid_data) > 0:\n",
    "                    basin_stat.update({\n",
    "                        f'{metric}_mean': valid_data.mean(),\n",
    "                        f'{metric}_std': valid_data.std(),\n",
    "                        f'{metric}_min': valid_data.min(),\n",
    "                        f'{metric}_max': valid_data.max(),\n",
    "                        f'{metric}_median': valid_data.median(),\n",
    "                        f'{metric}_q25': valid_data.quantile(0.25),\n",
    "                        f'{metric}_q75': valid_data.quantile(0.75)\n",
    "                    })\n",
    "                else:\n",
    "                    basin_stat.update({\n",
    "                        f'{metric}_mean': np.nan,\n",
    "                        f'{metric}_std': np.nan,\n",
    "                        f'{metric}_min': np.nan,\n",
    "                        f'{metric}_max': np.nan,\n",
    "                        f'{metric}_median': np.nan,\n",
    "                        f'{metric}_q25': np.nan,\n",
    "                        f'{metric}_q75': np.nan\n",
    "                    })\n",
    "        \n",
    "        # Add absolute PBIAS for ranking\n",
    "        if 'PBIAS_mean' in basin_stat:\n",
    "            basin_stat['abs_PBIAS_mean'] = abs(basin_stat['PBIAS_mean'])\n",
    "        \n",
    "        # Add performance categories\n",
    "        r_mean = basin_stat.get('r_mean', 0)\n",
    "        nse_mean = basin_stat.get('NSE_mean', -999)\n",
    "        \n",
    "        if r_mean >= 0.7 and nse_mean >= 0.5:\n",
    "            performance = 'Excellent'\n",
    "        elif r_mean >= 0.5 and nse_mean >= 0.3:\n",
    "            performance = 'Good'\n",
    "        elif r_mean >= 0.3 and nse_mean >= 0:\n",
    "            performance = 'Fair'\n",
    "        else:\n",
    "            performance = 'Poor'\n",
    "        \n",
    "        basin_stat['Performance_Category'] = performance\n",
    "        \n",
    "        basin_stats.append(basin_stat)\n",
    "    \n",
    "    return pd.DataFrame(basin_stats)\n",
    "\n",
    "def create_basin_comparison_6models(merged_df):\n",
    "    \"\"\"Create detailed basin comparison with station-level data - 6-model ensemble\"\"\"\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for basin_name in merged_df['Basin'].unique():\n",
    "        basin_data = merged_df[merged_df['Basin'] == basin_name]\n",
    "        \n",
    "        for _, station in basin_data.iterrows():\n",
    "            comparison_data.append({\n",
    "                'Basin': basin_name,\n",
    "                'Station_ID': station['Station_ID'],\n",
    "                'Station_Name': station.get('Station_Name', f\"Station_{station['Station_ID']}\"),\n",
    "                'Latitude': station.get('Latitude', np.nan),\n",
    "                'Longitude': station.get('Longitude', np.nan),\n",
    "                'Model': station['Model'],\n",
    "                'Ensemble_Type': '6_Models_Uniform',\n",
    "                'r': station.get('r', np.nan),\n",
    "                'NSE': station.get('NSE', np.nan),\n",
    "                'RMSE': station.get('RMSE', np.nan),\n",
    "                'MAE': station.get('MAE', np.nan),\n",
    "                'PBIAS': station.get('PBIAS', np.nan),\n",
    "                'abs_PBIAS': abs(station.get('PBIAS', 0)) if not np.isnan(station.get('PBIAS', np.nan)) else np.nan,\n",
    "                'Coverage_Ratio': station.get('Coverage_Ratio', np.nan),\n",
    "                'Valid_Months': station.get('Valid_Months', np.nan),\n",
    "                'Missing_Months': station.get('Missing_Months', np.nan),\n",
    "                'Performance_Grade': classify_station_performance(station)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "def classify_station_performance(station):\n",
    "    \"\"\"Classify individual station performance\"\"\"\n",
    "    r = station.get('r', 0)\n",
    "    nse = station.get('NSE', -999)\n",
    "    \n",
    "    if r >= 0.8 and nse >= 0.7:\n",
    "        return 'A+'\n",
    "    elif r >= 0.7 and nse >= 0.5:\n",
    "        return 'A'\n",
    "    elif r >= 0.5 and nse >= 0.3:\n",
    "        return 'B'\n",
    "    elif r >= 0.3 and nse >= 0:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "def rank_basins_by_performance_6models(basin_stats):\n",
    "    \"\"\"Rank basins based on multiple performance criteria - 6-model ensemble\"\"\"\n",
    "    \n",
    "    # Define which metrics are better when higher or lower\n",
    "    higher_better = ['r_mean', 'NSE_mean', 'Coverage_Ratio_mean']\n",
    "    lower_better = ['RMSE_mean', 'MAE_mean', 'abs_PBIAS_mean']\n",
    "    \n",
    "    rankings_df = basin_stats.copy()\n",
    "    \n",
    "    # Rank for each metric (1 is best)\n",
    "    for metric in higher_better:\n",
    "        if metric in rankings_df.columns:\n",
    "            rankings_df[f'{metric}_rank'] = rankings_df[metric].rank(ascending=False, na_option='bottom')\n",
    "    \n",
    "    for metric in lower_better:\n",
    "        if metric in rankings_df.columns:\n",
    "            rankings_df[f'{metric}_rank'] = rankings_df[metric].rank(ascending=True, na_option='bottom')\n",
    "    \n",
    "    # Calculate average rank across all metrics\n",
    "    rank_columns = [col for col in rankings_df.columns if col.endswith('_rank')]\n",
    "    \n",
    "    if rank_columns:\n",
    "        rankings_df['avg_rank'] = rankings_df[rank_columns].mean(axis=1)\n",
    "        rankings_df['overall_rank'] = rankings_df['avg_rank'].rank(na_option='bottom')\n",
    "    else:\n",
    "        rankings_df['avg_rank'] = np.nan\n",
    "        rankings_df['overall_rank'] = np.nan\n",
    "    \n",
    "    # Add weighted performance score (emphasizing correlation and NSE)\n",
    "    rankings_df['weighted_score'] = (\n",
    "        rankings_df.get('r_mean', 0) * 0.4 +\n",
    "        rankings_df.get('NSE_mean', 0) * 0.3 +\n",
    "        (1 - rankings_df.get('abs_PBIAS_mean', 100) / 100) * 0.2 +\n",
    "        rankings_df.get('Coverage_Ratio_mean', 0) * 0.1\n",
    "    )\n",
    "    \n",
    "    # Sort by average rank\n",
    "    rankings_df = rankings_df.sort_values('avg_rank', na_position='last')\n",
    "    \n",
    "    return rankings_df\n",
    "\n",
    "def save_comprehensive_summary_6models(basin_stats, basin_comparison, rankings, merged_df, output_dir):\n",
    "    \"\"\"Save a comprehensive summary with multiple sheets - 6-model ensemble\"\"\"\n",
    "    \n",
    "    summary_file = os.path.join(output_dir, 'Ensemble_6Models_Basin_Validation_Summary.xlsx')\n",
    "    \n",
    "    with pd.ExcelWriter(summary_file, engine='openpyxl') as writer:\n",
    "        # Main summary statistics\n",
    "        basin_stats.to_excel(writer, sheet_name='Basin_Statistics', index=False)\n",
    "        \n",
    "        # Rankings\n",
    "        rankings.to_excel(writer, sheet_name='Basin_Rankings', index=False)\n",
    "        \n",
    "        # Detailed comparison\n",
    "        basin_comparison.to_excel(writer, sheet_name='Station_Details', index=False)\n",
    "        \n",
    "        # Key metrics summary\n",
    "        key_metrics = rankings[['Basin', 'Station_Count', 'r_mean', 'NSE_mean', 'RMSE_mean', \n",
    "                              'PBIAS_mean', 'Coverage_Ratio_mean', 'Performance_Category',\n",
    "                              'weighted_score', 'overall_rank']].copy()\n",
    "        key_metrics = key_metrics.sort_values('overall_rank')\n",
    "        key_metrics.to_excel(writer, sheet_name='Key_Metrics_Summary', index=False)\n",
    "        \n",
    "        # Station count per basin\n",
    "        station_counts = merged_df.groupby('Basin').size().reset_index(name='Station_Count')\n",
    "        station_counts.to_excel(writer, sheet_name='Station_Counts', index=False)\n",
    "        \n",
    "        # Performance categories\n",
    "        performance_categories = create_performance_categories_6models(rankings)\n",
    "        performance_categories.to_excel(writer, sheet_name='Performance_Categories', index=False)\n",
    "        \n",
    "        # Station performance grades\n",
    "        grade_summary = basin_comparison.groupby(['Basin', 'Performance_Grade']).size().unstack(fill_value=0)\n",
    "        grade_summary.to_excel(writer, sheet_name='Station_Grades_by_Basin')\n",
    "        \n",
    "        # Coverage analysis\n",
    "        coverage_analysis = analyze_coverage_by_basin(merged_df)\n",
    "        coverage_analysis.to_excel(writer, sheet_name='Coverage_Analysis', index=False)\n",
    "\n",
    "def create_performance_categories_6models(rankings):\n",
    "    \"\"\"Categorize basin performance - 6-model ensemble\"\"\"\n",
    "    \n",
    "    categories = []\n",
    "    \n",
    "    for _, basin in rankings.iterrows():\n",
    "        basin_name = basin['Basin']\n",
    "        \n",
    "        # Enhanced categorization\n",
    "        r_mean = basin.get('r_mean', 0)\n",
    "        nse_mean = basin.get('NSE_mean', -999)\n",
    "        coverage = basin.get('Coverage_Ratio_mean', 0)\n",
    "        \n",
    "        category = basin.get('Performance_Category', 'Unknown')\n",
    "        \n",
    "        # Add detailed assessment\n",
    "        if r_mean >= 0.8 and nse_mean >= 0.7:\n",
    "            detailed_category = 'Outstanding'\n",
    "        elif r_mean >= 0.7 and nse_mean >= 0.5:\n",
    "            detailed_category = 'Excellent'\n",
    "        elif r_mean >= 0.5 and nse_mean >= 0.3:\n",
    "            detailed_category = 'Good'\n",
    "        elif r_mean >= 0.3 and nse_mean >= 0:\n",
    "            detailed_category = 'Fair'\n",
    "        else:\n",
    "            detailed_category = 'Poor'\n",
    "        \n",
    "        categories.append({\n",
    "            'Basin': basin_name,\n",
    "            'Performance_Category': category,\n",
    "            'Detailed_Category': detailed_category,\n",
    "            'r_mean': r_mean,\n",
    "            'NSE_mean': nse_mean,\n",
    "            'RMSE_mean': basin.get('RMSE_mean', np.nan),\n",
    "            'Coverage_Ratio_mean': coverage,\n",
    "            'Station_Count': basin.get('Station_Count', 0),\n",
    "            'Overall_Rank': basin.get('overall_rank', np.nan),\n",
    "            'Weighted_Score': basin.get('weighted_score', np.nan),\n",
    "            'Ensemble_Type': '6_Models_Uniform'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(categories)\n",
    "\n",
    "def analyze_coverage_by_basin(merged_df):\n",
    "    \"\"\"Analyze data coverage patterns by basin\"\"\"\n",
    "    \n",
    "    coverage_analysis = []\n",
    "    \n",
    "    for basin_name in merged_df['Basin'].unique():\n",
    "        basin_data = merged_df[merged_df['Basin'] == basin_name]\n",
    "        \n",
    "        coverage_stats = {\n",
    "            'Basin': basin_name,\n",
    "            'Station_Count': len(basin_data),\n",
    "            'Avg_Coverage_Ratio': basin_data['Coverage_Ratio'].mean(),\n",
    "            'Min_Coverage_Ratio': basin_data['Coverage_Ratio'].min(),\n",
    "            'Max_Coverage_Ratio': basin_data['Coverage_Ratio'].max(),\n",
    "            'Stations_Full_Coverage': (basin_data['Coverage_Ratio'] >= 1.0).sum(),\n",
    "            'Stations_High_Coverage': (basin_data['Coverage_Ratio'] >= 0.8).sum(),\n",
    "            'Stations_Low_Coverage': (basin_data['Coverage_Ratio'] < 0.5).sum(),\n",
    "            'Avg_Valid_Months': basin_data['Valid_Months'].mean(),\n",
    "            'Total_Missing_Months': basin_data['Missing_Months'].sum()\n",
    "        }\n",
    "        \n",
    "        coverage_analysis.append(coverage_stats)\n",
    "    \n",
    "    return pd.DataFrame(coverage_analysis)\n",
    "\n",
    "def create_ensemble_comparison(merged_df, output_dir):\n",
    "    \"\"\"Create comparison between 3-model and 6-model ensembles if 3-model data exists\"\"\"\n",
    "    \n",
    "    # Check if 3-model results exist\n",
    "    three_model_file = r\"D:\\RICAAR\\Pr.New.Stations.Selection\\ensemble.model\\ncfiles\\Validation.results\\ACCORDING.TO.BASIN\\Station_Basin_Validation_Data.xlsx\"\n",
    "    \n",
    "    if os.path.exists(three_model_file):\n",
    "        print(\"üìä Found 3-model ensemble data - creating comparison...\")\n",
    "        \n",
    "        try:\n",
    "            # Read 3-model data\n",
    "            three_model_df = pd.read_excel(three_model_file)\n",
    "            three_model_df['Ensemble_Type'] = '3_Models_Basin_Specific'\n",
    "            \n",
    "            # Current 6-model data\n",
    "            six_model_df = merged_df.copy()\n",
    "            six_model_df['Ensemble_Type'] = '6_Models_Uniform'\n",
    "            \n",
    "            # Create comparison\n",
    "            comparison_data = []\n",
    "            \n",
    "            # Get common stations\n",
    "            common_stations = set(three_model_df['Station_ID']) & set(six_model_df['Station_ID'])\n",
    "            \n",
    "            for station_id in common_stations:\n",
    "                three_data = three_model_df[three_model_df['Station_ID'] == station_id].iloc[0]\n",
    "                six_data = six_model_df[six_model_df['Station_ID'] == station_id].iloc[0]\n",
    "                \n",
    "                comparison_data.append({\n",
    "                    'Station_ID': station_id,\n",
    "                    'Basin': six_data.get('Basin', 'Unknown'),\n",
    "                    '3Model_r': three_data.get('r', np.nan),\n",
    "                    '6Model_r': six_data.get('r', np.nan),\n",
    "                    '3Model_NSE': three_data.get('NSE', np.nan),\n",
    "                    '6Model_NSE': six_data.get('NSE', np.nan),\n",
    "                    '3Model_RMSE': three_data.get('RMSE', np.nan),\n",
    "                    '6Model_RMSE': six_data.get('RMSE', np.nan),\n",
    "                    '3Model_PBIAS': three_data.get('PBIAS', np.nan),\n",
    "                    '6Model_PBIAS': six_data.get('PBIAS', np.nan),\n",
    "                    'r_Improvement': six_data.get('r', 0) - three_data.get('r', 0),\n",
    "                    'NSE_Improvement': six_data.get('NSE', 0) - three_data.get('NSE', 0),\n",
    "                    'RMSE_Change': six_data.get('RMSE', 0) - three_data.get('RMSE', 0),\n",
    "                    'Better_Ensemble': determine_better_ensemble(three_data, six_data)\n",
    "                })\n",
    "            \n",
    "            comparison_df = pd.DataFrame(comparison_data)\n",
    "            \n",
    "            # Save comparison\n",
    "            comparison_file = os.path.join(output_dir, 'Ensemble_Comparison_3vs6_Models.xlsx')\n",
    "            comparison_df.to_excel(comparison_file, index=False)\n",
    "            \n",
    "            print(f\"‚úÖ Ensemble comparison saved to: {comparison_file}\")\n",
    "            print(f\"üìä Compared {len(common_stations)} common stations\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not create ensemble comparison: {e}\")\n",
    "\n",
    "def determine_better_ensemble(three_data, six_data):\n",
    "    \"\"\"Determine which ensemble performs better for a station\"\"\"\n",
    "    \n",
    "    # Simple scoring based on r and NSE\n",
    "    three_score = (three_data.get('r', 0) + three_data.get('NSE', 0)) / 2\n",
    "    six_score = (six_data.get('r', 0) + six_data.get('NSE', 0)) / 2\n",
    "    \n",
    "    if six_score > three_score + 0.05:  # 5% threshold\n",
    "        return '6-Model Better'\n",
    "    elif three_score > six_score + 0.05:\n",
    "        return '3-Model Better'\n",
    "    else:\n",
    "        return 'Similar Performance'\n",
    "\n",
    "def print_basin_summary_6models(basin_stats, rankings):\n",
    "    \"\"\"Print a summary of basin performance - 6-model ensemble\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"6-MODEL ENSEMBLE BASIN PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"Total basins analyzed: {len(basin_stats)}\")\n",
    "    print(f\"Total stations: {basin_stats['Station_Count'].sum()}\")\n",
    "    print(f\"Ensemble approach: Uniform 6-model ensemble\")\n",
    "    \n",
    "    print(f\"\\nüèÜ TOP 3 PERFORMING BASINS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    top_basins = rankings.head(3)\n",
    "    for i, (_, basin) in enumerate(top_basins.iterrows(), 1):\n",
    "        print(f\"\\n{i}. {basin['Basin']}\")\n",
    "        print(f\"   Stations: {basin['Station_Count']}\")\n",
    "        print(f\"   Correlation: {basin.get('r_mean', 0):.3f}\")\n",
    "        print(f\"   NSE: {basin.get('NSE_mean', 0):.3f}\")\n",
    "        print(f\"   RMSE: {basin.get('RMSE_mean', 0):.2f}\")\n",
    "        print(f\"   Category: {basin.get('Performance_Category', 'Unknown')}\")\n",
    "        print(f\"   Overall Rank: {basin.get('overall_rank', 0):.0f}\")\n",
    "    \n",
    "    print(f\"\\nüìä OVERALL ENSEMBLE STATISTICS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Overall statistics\n",
    "    overall_r = basin_stats['r_mean'].mean()\n",
    "    overall_nse = basin_stats['NSE_mean'].mean()\n",
    "    overall_rmse = basin_stats['RMSE_mean'].mean()\n",
    "    overall_coverage = basin_stats['Coverage_Ratio_mean'].mean()\n",
    "    \n",
    "    print(f\"Average Correlation: {overall_r:.3f}\")\n",
    "    print(f\"Average NSE: {overall_nse:.3f}\")\n",
    "    print(f\"Average RMSE: {overall_rmse:.2f}\")\n",
    "    print(f\"Average Coverage: {overall_coverage:.3f}\")\n",
    "    \n",
    "    # Performance categories\n",
    "    category_counts = basin_stats['Performance_Category'].value_counts()\n",
    "    print(f\"\\nüèÖ PERFORMANCE CATEGORIES:\")\n",
    "    print(\"-\" * 40)\n",
    "    for category, count in category_counts.items():\n",
    "        print(f\"{category}: {count} basins\")\n",
    "    \n",
    "    print(f\"\\nüéØ KEY INFORMATION:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"‚úÖ Uniform 6-model ensemble applied to all basins\")\n",
    "    print(\"üìä Models: CMCC-CM2-SR5, CNRM-ESM2-1, EC-Earth3-Veg, IPSL-CM6A-LR, MPI-ESM1-2-LR, NorESM2-MM\")\n",
    "    print(\"üîç Results show ensemble performance across different hydrological regions\")\n",
    "    print(\"üìà Basin-specific performance variations reflect regional climate model accuracy\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_basin_validation_analysis_6models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0c0e4-eb3c-4fa7-ad98-3fd320691e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
